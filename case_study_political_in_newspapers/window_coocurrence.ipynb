{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import os, sys\n",
    "\n",
    "sys.path = list(set(sys.path + [ '../common' ]))\n",
    "\n",
    "import utility\n",
    "import text_corpus\n",
    "import corpus_vectorizer\n",
    "import types\n",
    "\n",
    "# df = pd.read_excel('./data/year+text_window.xlsx')\n",
    "# df.to_csv('./data/year+text_window.txt', sep='\\t')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFrameReader:\n",
    "\n",
    "    def __init__(self, df, year=None):\n",
    "        \n",
    "        self.df = df\n",
    "        \n",
    "        if year is not None:\n",
    "            self.df = self.df[self.df.year == year]\n",
    "                              \n",
    "        if len(self.df[self.df.txt.isna()]) > 0:\n",
    "            print('Warn: {} n/a rows encountered'.format(len(self.df[self.df.txt.isna()])))\n",
    "            self.df = self.df.dropna()\n",
    "            \n",
    "        self.iterator = None\n",
    "        self.metadata = [ types.SimpleNamespace(filename=str(i), year=r) for i, r in enumerate(self.df.year.values)]\n",
    "        self.metadict = { x.filename: x for x in (self.metadata or [])}\n",
    "        self.filenames = [ x.filename for x in self.metadata ]\n",
    "        \n",
    "    def __iter__(self):\n",
    "                              \n",
    "        self.iterator = None\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "                              \n",
    "        if self.iterator is None:\n",
    "            self.iterator = self.get_iterator()\n",
    "                              \n",
    "        return next(self.iterator)\n",
    "\n",
    "    def get_iterator(self):\n",
    "        return ((str(i), x) for i,x in enumerate(self.df.txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warn: 40 n/a rows encountered\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_coocurrence_matrix(reader, **kwargs):\n",
    "\n",
    "    corpus = text_corpus.ProcessedCorpus(reader, isalnum=False, **kwargs)\n",
    "    vectorizer = corpus_vectorizer.CorpusVectorizer(lowercase=False)\n",
    "    vectorizer.fit_transform(corpus)\n",
    "        \n",
    "    term_term_matrix = np.dot(vectorizer.X.T, vectorizer.X)\n",
    "        \n",
    "    term_term_matrix = scipy.sparse.triu(term_term_matrix, 1)\n",
    "        \n",
    "    coo = term_term_matrix\n",
    "    id2token = { i: t for t,i in vectorizer.vocabulary.items()}\n",
    "    cdf = pd.DataFrame({\n",
    "        'w1_id': coo.row,\n",
    "        'w2_id': coo.col,\n",
    "        'value': coo.data\n",
    "    })[['w1_id', 'w2_id', 'value']].sort_values(['w1_id', 'w2_id'])\\\n",
    "        .reset_index(drop=True)\n",
    "    cdf['w1'] = cdf.w1_id.apply(lambda x: id2token[x])\n",
    "    cdf['w2'] = cdf.w2_id.apply(lambda x: id2token[x])\n",
    "    \n",
    "    return cdf[['w1', 'w2', 'value']]\n",
    "\n",
    "def compute_co_ocurrence_for_year(source_filename, year, result_filename):\n",
    "    \n",
    "    df = pd.read_csv(source_filename, sep='\\t')[['year', 'txt']]\n",
    "\n",
    "    reader = DataFrameReader(df, year)\n",
    "\n",
    "    kwargs = dict(to_lower=True, deacc=False, min_len=1, max_len=None, numerals=False)\n",
    "\n",
    "    coo_df = compute_coocurrence_matrix(reader, **kwargs)\n",
    "    coo_df.to_excel(result_filename)\n",
    "\n",
    "compute_co_ocurrence_for_year('./data/year+text_window.txt', 1957, 'test_1957.xlsx')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "......."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  w1 w2  value\n",
      "0  A  B      2\n",
      "1  A  C      1\n",
      "2  A  F      1\n",
      "3  B  C      3\n",
      "4  B  D      1\n",
      "5  B  E      1\n",
      "6  B  F      1\n",
      "7  C  D      1\n",
      "8  E  F      2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 7 tests in 0.063s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x7f2b4d58db00>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest\n",
    "import corpus_vectorizer\n",
    "\n",
    "class Test_DfReader(unittest.TestCase):\n",
    "    \n",
    "    def setUp(self):\n",
    "        pass\n",
    "    \n",
    "    def create_test_dataframe(self):\n",
    "        data = [ \n",
    "            (2000, 'A B C'),\n",
    "            (2000, 'B C D'), \n",
    "            (2001, 'C B'),\n",
    "            (2003, 'A B F'),\n",
    "            (2003, 'E B'),\n",
    "            (2003, 'F E E')\n",
    "        ]\n",
    "        df = pd.DataFrame(data, columns=['year', 'txt'])\n",
    "        return df\n",
    "    \n",
    "    def test_reader_with_all_documents(self):\n",
    "        df = self.create_test_dataframe()\n",
    "        reader = DataFrameReader(df)\n",
    "        result = [x for x in reader]\n",
    "        expected = [('0', 'A B C'), ('1', 'B C D'), ('2', 'C B'), ('3', 'A B F'), ('4', 'E B'), ('5', 'F E E')]\n",
    "        self.assertEqual(expected, result)\n",
    "        self.assertEqual(['0', '1', '2', '3', '4', '5'], reader.filenames)\n",
    "        self.assertEqual([\n",
    "                types.SimpleNamespace(filename='0', year=2000),\n",
    "                types.SimpleNamespace(filename='1', year=2000),\n",
    "                types.SimpleNamespace(filename='2', year=2001),\n",
    "                types.SimpleNamespace(filename='3', year=2003),\n",
    "                types.SimpleNamespace(filename='4', year=2003),\n",
    "                types.SimpleNamespace(filename='5', year=2003)\n",
    "            ], reader.metadata\n",
    "        )\n",
    "        \n",
    "    def test_reader_with_given_year(self):\n",
    "        df = self.create_test_dataframe()\n",
    "        reader = DataFrameReader(df, 2003)\n",
    "        result = [x for x in reader]\n",
    "        expected = [('0', 'A B F'), ('1', 'E B'), ('2', 'F E E')]\n",
    "        self.assertEqual(expected, result)\n",
    "        self.assertEqual(['0', '1', '2'], reader.filenames)\n",
    "        self.assertEqual([\n",
    "                types.SimpleNamespace(filename='0', year=2003),\n",
    "                types.SimpleNamespace(filename='1', year=2003),\n",
    "                types.SimpleNamespace(filename='2', year=2003)\n",
    "            ], reader.metadata\n",
    "        )\n",
    "\n",
    "class Test_DfVectorize(unittest.TestCase):\n",
    "    \n",
    "    def setUp(self):\n",
    "        pass\n",
    "    \n",
    "    def create_test_dataframe(self):\n",
    "        data = [ \n",
    "            (2000, 'A B C'),\n",
    "            (2000, 'B C D'), \n",
    "            (2001, 'C B'),\n",
    "            (2003, 'A B F'),\n",
    "            (2003, 'E B'),\n",
    "            (2003, 'F E E')\n",
    "        ]\n",
    "        df = pd.DataFrame(data, columns=['year', 'txt'])\n",
    "        return df\n",
    "    \n",
    "    def create_corpus(self):\n",
    "        df = self.create_test_dataframe()\n",
    "        reader = DataFrameReader(df)\n",
    "        kwargs = dict(isalnum=False, to_lower=False, deacc=False, min_len=0, max_len=None, numerals=False)\n",
    "        corpus = text_corpus.ProcessedCorpus(reader, **kwargs)\n",
    "        return corpus\n",
    "    \n",
    "    def test_corpus_text_stream(self):\n",
    "        df = self.create_test_dataframe()\n",
    "        reader = DataFrameReader(df)\n",
    "        corpus = text_corpus.CorpusTextStream(reader)\n",
    "        result = [ x for x in corpus.documents()]\n",
    "        expected = [('0', 'A B C'), ('1', 'B C D'), ('2', 'C B'), ('3', 'A B F'), ('4', 'E B'), ('5', 'F E E')]\n",
    "        self.assertEqual(expected, result)\n",
    "        \n",
    "    def test_corpus_token_stream(self):\n",
    "        df = self.create_test_dataframe()\n",
    "        reader = DataFrameReader(df)\n",
    "        corpus = text_corpus.CorpusTokenStream(reader)\n",
    "        result = [ x for x in corpus.documents()]\n",
    "        expected = [('0', ['A', 'B', 'C']), ('1', ['B', 'C', 'D']), ('2', ['C', 'B']), ('3', ['A', 'B', 'F']), ('4', ['E', 'B']), ('5', ['F', 'E', 'E'])]\n",
    "        self.assertEqual(expected, result)\n",
    "\n",
    "    def test_processed_corpus_token_stream(self):\n",
    "        df = self.create_test_dataframe()\n",
    "        reader = DataFrameReader(df)\n",
    "        kwargs = dict(isalnum=False, to_lower=False, deacc=False, min_len=0, max_len=None, numerals=False)\n",
    "        corpus = text_corpus.ProcessedCorpus(reader, **kwargs)\n",
    "        result = [ x for x in corpus.documents()]\n",
    "        expected = [('0', ['A', 'B', 'C']), ('1', ['B', 'C', 'D']), ('2', ['C', 'B']), ('3', ['A', 'B', 'F']), ('4', ['E', 'B']), ('5', ['F', 'E', 'E'])]\n",
    "        self.assertEqual(expected, result)\n",
    "        \n",
    "    def test_fit_transform_gives_document_term_matrix(self):\n",
    "        reader = DataFrameReader(self.create_test_dataframe())\n",
    "        kwargs = dict(to_lower=False, deacc=False, min_len=1, max_len=None, numerals=False)\n",
    "        corpus = text_corpus.ProcessedCorpus(reader, isalnum=False, **kwargs)\n",
    "        vectorizer = corpus_vectorizer.CorpusVectorizer(lowercase=False)\n",
    "        vectorizer.fit_transform(corpus)\n",
    "        expected = np.asarray([\n",
    "            [1, 1, 1, 0, 0, 0],\n",
    "            [0, 1, 1, 1, 0, 0],\n",
    "            [0, 1, 1, 0, 0, 0],\n",
    "            [1, 1, 0, 0, 0, 1],\n",
    "            [0, 1, 0, 0, 1, 0],\n",
    "            [0, 0, 0, 0, 2, 1]\n",
    "        ])\n",
    "        self.assertTrue((expected == vectorizer.X).all())\n",
    "        results = vectorizer.vocabulary\n",
    "        expected = {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'F': 5, 'E': 4 }\n",
    "        self.assertEqual(expected, results)\n",
    "\n",
    "    def test_AxAt_of_document_term_matrix_gives_term_term_matrix(self):\n",
    "        reader = DataFrameReader(self.create_test_dataframe())\n",
    "        kwargs = dict(to_lower=False, deacc=False, min_len=1, max_len=None, numerals=False)\n",
    "        corpus = text_corpus.ProcessedCorpus(reader, isalnum=False, **kwargs)\n",
    "        vectorizer = corpus_vectorizer.CorpusVectorizer(lowercase=False)\n",
    "        vectorizer.fit_transform(corpus)\n",
    "        \n",
    "        term_term_matrix = np.dot(vectorizer.X.T, vectorizer.X)\n",
    "        \n",
    "        #print(term_term_matrix.toarray())\n",
    "        \n",
    "        expected = np.asarray([\n",
    "            [2, 2, 1, 0, 0, 1],\n",
    "            [2, 5, 3, 1, 1, 1],\n",
    "            [1, 3, 3, 1, 0, 0],\n",
    "            [0, 1, 1, 1, 0, 0],\n",
    "            [0, 1, 0, 0, 5, 2],\n",
    "            [1, 1, 0, 0, 2, 2]\n",
    "        ])\n",
    "        self.assertTrue((expected == term_term_matrix).all())\n",
    "        \n",
    "        term_term_matrix = scipy.sparse.triu(term_term_matrix, 1)\n",
    "        \n",
    "        #print(term_term_matrix.todense())\n",
    "        #print(term_term_matrix)\n",
    "        coo = term_term_matrix\n",
    "        id2token = { i: t for t,i in vectorizer.vocabulary.items()}\n",
    "        cdf = pd.DataFrame({\n",
    "            'w1_id': coo.row,\n",
    "            'w2_id': coo.col,\n",
    "            'value': coo.data\n",
    "        })[['w1_id', 'w2_id', 'value']].sort_values(['w1_id', 'w2_id'])\\\n",
    "            .reset_index(drop=True)\n",
    "        cdf['w1'] = cdf.w1_id.apply(lambda x: id2token[x])\n",
    "        cdf['w2'] = cdf.w2_id.apply(lambda x: id2token[x])\n",
    "        print(cdf[['w1', 'w2', 'value']])\n",
    "        \n",
    "unittest.main(argv=['first-arg-is-ignored'], exit=False)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
