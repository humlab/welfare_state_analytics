{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process R data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys, os\n",
    "\n",
    "\n",
    "root_folder = os.path.abspath(os.path.join(globals()['_dh'][-1], \"../../..\"))\n",
    "corpus_folder = os.path.join(root_folder, \"data/textblock_politisk\")\n",
    "\n",
    "sys.path = [ root_folder ] + sys.path\n",
    "\n",
    "import westac.notebooks.political_in_newspapers.corpus_data as corpus_data\n",
    "\n",
    "import ipywidgets\n",
    "#from beakerx import *\n",
    "#from beakerx.object import beakerx\n",
    "from IPython.display import display\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import westac.corpus.vectorized_corpus as vectorized_corpus\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load DTM, document index and vocabulary\n",
    "This data is loaded from CSV files exported from R (drm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import westac.notebooks.political_in_newspapers.corpus_data as corpus_data\n",
    "df_corpus, df_document, df_vocabulary = corpus_data.load(corpus_folder)\n",
    "id2token = df_vocabulary['token'].to_dict()\n",
    "\n",
    "df_tf = df_corpus\\\n",
    "    .groupby(['document_id']).agg(\n",
    "        term_count=('tf', 'sum')\n",
    "    )\n",
    "df_document = df_document.merge(df_tf, how='inner', right_index=True, left_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document size distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def plot_document_size_distribution():\n",
    "\n",
    "    df = df_document\\\n",
    "        .groupby('term_count')\\\n",
    "        .size()\n",
    "\n",
    "    dx = pd.DataFrame({ 'term_count': list(range(0, df.index.max() + 1))}).set_index('term_count')\n",
    "    df = dx.join(df.rename('x'), how='left').fillna(0).astype(np.int)\n",
    "\n",
    "    ax = df\\\n",
    "        .plot\\\n",
    "        .bar(figsize=(20,10), rot=45);\n",
    "\n",
    "    ticks = ax.xaxis.get_ticklocs();\n",
    "    ticklabels = [ l.get_text() for l in ax.xaxis.get_ticklabels() ];\n",
    "    ax.xaxis.set_ticks(ticks[::100]);\n",
    "    ax.xaxis.set_ticklabels(ticklabels[::100]);\n",
    "\n",
    "    return df\n",
    "\n",
    "df = plot_document_size_distribution()\n",
    "\n",
    "#print(df.describe())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of documents per year and publication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_document\\\n",
    "    .groupby(['year', 'publication'])\\\n",
    "    .agg(document_count=('doc_id', 'nunique'))\\\n",
    "    .reset_index()\\\n",
    "    .set_index(['year', 'publication'])\n",
    "\n",
    "df\\\n",
    "    .unstack('publication')\\\n",
    "    .plot(kind='bar', subplots=True, figsize=(20,20), layout=(2,2), rot=45);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_document\\\n",
    "    .groupby(['year', 'publication'])\\\n",
    "    .agg(term_count=('term_count', 'sum'))\\\n",
    "    .reset_index()\\\n",
    "    .set_index(['year', 'publication'])\\\n",
    "    .unstack('publication')\n",
    "    \n",
    "df.plot(kind='bar', subplots=True, figsize=(25,25), layout=(2,2), rot=45);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print data sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('Corpus metrics, source \"dtm1.rds\", arrays drm$i, drm$j, drm$v')\n",
    "print('  {} max document ID'.format(df_corpus.document_id.max()))\n",
    "print('  {} unique document ID'.format(df_corpus.document_id.unique().shape[0]))\n",
    "print('  {} max token ID'.format(df_corpus.token_id.max()))\n",
    "print('  {} unique token ID'.format(df_corpus.token_id.unique().shape[0]))\n",
    "\n",
    "print('Document metrics, source \"dtm1.rds\", arrays drm$dimnames[1]')\n",
    "print('  {} max ID'.format(df_document.index.max()))\n",
    "print('  {} unique ID'.format(df_document.index.unique().shape[0]))\n",
    "print('  {} unique names'.format(df_document.doc_id.unique().shape[0]))\n",
    "\n",
    "print('Vocabulary metrics, source \"dtm1.rds\", arrays drm$dimnames[2]')\n",
    "print('  {} max ID'.format(df_vocabulary.index.max()))\n",
    "print('  {} unique ID'.format(df_vocabulary.index.unique().shape[0]))\n",
    "print('  {} unique token'.format(df_vocabulary.token.unique().shape[0]))\n",
    "\n",
    "#df_document.groupby('doc_id').filter(lambda x: len(x) > 1).head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
