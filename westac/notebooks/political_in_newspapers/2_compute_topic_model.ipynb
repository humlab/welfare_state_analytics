{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Analysis - Topic Modelling\n",
    "### <span style='color: green'>SETUP </span> Prepare and Setup Notebook <span style='float: right; color: red'>MANDATORY</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
    },
    {
     "data": {
      "text/html": "\n    <div class=\"bk-root\">\n        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n        <span id=\"1002\">Loading BokehJS ...</span>\n    </div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  var JS_MIME_TYPE = 'application/javascript';\n  var HTML_MIME_TYPE = 'text/html';\n  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n  var CLASS_NAME = 'output_bokeh rendered_html';\n\n  /**\n   * Render data to the DOM node\n   */\n  function render(props, node) {\n    var script = document.createElement(\"script\");\n    node.appendChild(script);\n  }\n\n  /**\n   * Handle when an output is cleared or removed\n   */\n  function handleClearOutput(event, handle) {\n    var cell = handle.cell;\n\n    var id = cell.output_area._bokeh_element_id;\n    var server_id = cell.output_area._bokeh_server_id;\n    // Clean up Bokeh references\n    if (id != null && id in Bokeh.index) {\n      Bokeh.index[id].model.document.clear();\n      delete Bokeh.index[id];\n    }\n\n    if (server_id !== undefined) {\n      // Clean up Bokeh references\n      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n      cell.notebook.kernel.execute(cmd, {\n        iopub: {\n          output: function(msg) {\n            var id = msg.content.text.trim();\n            if (id in Bokeh.index) {\n              Bokeh.index[id].model.document.clear();\n              delete Bokeh.index[id];\n            }\n          }\n        }\n      });\n      // Destroy server and session\n      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n      cell.notebook.kernel.execute(cmd);\n    }\n  }\n\n  /**\n   * Handle when a new output is added\n   */\n  function handleAddOutput(event, handle) {\n    var output_area = handle.output_area;\n    var output = handle.output;\n\n    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n      return\n    }\n\n    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n\n    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n      // store reference to embed id on output_area\n      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n    }\n    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n      var bk_div = document.createElement(\"div\");\n      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n      var script_attrs = bk_div.children[0].attributes;\n      for (var i = 0; i < script_attrs.length; i++) {\n        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n      }\n      // store reference to server id on output_area\n      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n    }\n  }\n\n  function register_renderer(events, OutputArea) {\n\n    function append_mime(data, metadata, element) {\n      // create a DOM node to render to\n      var toinsert = this.create_output_subarea(\n        metadata,\n        CLASS_NAME,\n        EXEC_MIME_TYPE\n      );\n      this.keyboard_manager.register_events(toinsert);\n      // Render to node\n      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n      render(props, toinsert[toinsert.length - 1]);\n      element.append(toinsert);\n      return toinsert\n    }\n\n    /* Handle when an output is cleared or removed */\n    events.on('clear_output.CodeCell', handleClearOutput);\n    events.on('delete.Cell', handleClearOutput);\n\n    /* Handle when a new output is added */\n    events.on('output_added.OutputArea', handleAddOutput);\n\n    /**\n     * Register the mime type and append_mime function with output_area\n     */\n    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n      /* Is output safe? */\n      safe: true,\n      /* Index of renderer in `output_area.display_order` */\n      index: 0\n    });\n  }\n\n  // register the mime type if in Jupyter Notebook environment and previously unregistered\n  if (root.Jupyter !== undefined) {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  }\n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1002\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };var element = document.getElementById(\"1002\");\n  if (element == null) {\n    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1002' but no matching script tag was found. \")\n    return false;\n  }\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.3.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.3.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.3.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.3.4.min.js\"];\n  var css_urls = [];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1002\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));",
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1002\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };var element = document.getElementById(\"1002\");\n  if (element == null) {\n    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1002' but no matching script tag was found. \")\n    return false;\n  }\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.3.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.3.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.3.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.3.4.min.js\"];\n  var css_urls = [];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1002\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Setup\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys, os, collections, zipfile\n",
    "\n",
    "sys.path = [ '/home/roger/source/text_analytic_tools' ] + sys.path\n",
    "\n",
    "import re, typing.re\n",
    "import warnings\n",
    "import nltk, textacy, spacy \n",
    "import pickle\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "import bokeh, bokeh.plotting, bokeh.models, matplotlib.pyplot as plt\n",
    "\n",
    "import text_analytic_tools\n",
    "\n",
    "import text_analytic_tools.utility.utils as utility\n",
    "import text_analytic_tools.utility.widgets as widgets\n",
    "import text_analytic_tools.common.text_corpus as text_corpus\n",
    "import text_analytic_tools.common.textacy_utility as textacy_utility\n",
    "import text_analytic_tools.text_analysis.topic_model as topic_model\n",
    "import text_analytic_tools.text_analysis.topic_model_utility as topic_model_utility\n",
    "\n",
    "from beakerx.object import beakerx\n",
    "from beakerx import *\n",
    "from IPython.display import display, set_matplotlib_formats\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning) \n",
    "logger = utility.getLogger('corpus_text_analysis')\n",
    "\n",
    "utility.setup_default_pd_display(pd)\n",
    "\n",
    "from text_analytic_tools.config import get_current_domain\n",
    "\n",
    "domain_logic = get_current_domain()\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# set_matplotlib_formats('svg')\n",
    "bokeh.plotting.output_notebook()\n",
    "\n",
    "current_corpus_container = lambda: textacy_utility.CorpusContainer.container()\n",
    "current_corpus           = lambda: textacy_utility.CorpusContainer.corpus()\n",
    "current_state            = lambda: topic_model_utility.TopicModelContainer.singleton()\n",
    "current_data             = lambda: current_state().data\n",
    "current_topic_model      = lambda: current_state().topic_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#mkdir ./tmp\n",
    "#ln -s /home/roger/source/STTM ./lib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color: green;'>MODEL</span> Compute Topic Model Based on Raw Source Text Corpus<span style='color: red; float: right'>ALTERNATIVE #1</span>\n",
    "\n",
    "#### <span style='color: green'>PREPARE</span> Load (or Create) The Corpus <span style='float: right; color: red'>OPTIONAL</span>\n",
    "Setup a new corpus from the raw source text files the reside in a zip archive. This step uses the spaCy and textaCy frameworks for PoS tagging. This will take some time, several minutes, For large text files. If the same processing and filtering rules are repeatedly, then it is recommended to prepare the corpus once and for all using \"1_extract_corpus_text\" (also see next step).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-238bd012734a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mcontainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_corpus_container\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mload_corpus_gui\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay_corpus_load_gui\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdomain_logic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATA_FOLDER\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocument_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontainer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/source/text_analytic_tools/text_analytic_tools/notebooks_gui/load_corpus_gui.py\u001b[0m in \u001b[0;36mdisplay_corpus_load_gui\u001b[0;34m(data_folder, document_index, container, compute_ner, domain_logic)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mprogress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mipywidgets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIntProgress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'90%'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mipywidgets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'border'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'1px solid black'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0msource_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mutility\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidgets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Corpus'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'300px'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mlanguage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mutility\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidgets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Language'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlanguage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'en'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'180px'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import text_analytic_tools.notebooks_gui.load_corpus_gui as load_corpus_gui\n",
    "\n",
    "try:\n",
    "    container = current_corpus_container()\n",
    "    load_corpus_gui.display_corpus_load_gui(domain_logic.DATA_FOLDER, document_index=None, container=container)\n",
    "except Exception as ex:\n",
    "    raise\n",
    "    logger.error(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style='color: green;'>MODEL</span> Compute the Topic Model<span style='color: red; float: right'>OPTIONAL</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import topic_model_gui\n",
    "\n",
    "try:\n",
    "    gui = topic_model_gui.TextacyCorpusUserInterface(\n",
    "        data_folder=domain_logic.DATA_FOLDER,\n",
    "        state=current_state(),\n",
    "        document_index=domain_logic.compile_documents(current_corpus()),\n",
    "        tagset=domain_logic.get_tagset(),\n",
    "        substitution_filename=domain_logic.SUBSTITUTION_FILENAME\n",
    "    )\n",
    "    gui.display(current_corpus())\n",
    "    \n",
    "except Exception as ex:\n",
    "    raise\n",
    "    logger.error(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color: green'>MODEL </span> Compute Topic Model Based on a Previously Prepared Text Corpus <span style='float: right; color: red'>ALTERNATIVE #2</span>\n",
    "This step loads a text corpus consisting of pre-processed tokens. This is much faster compered to previous step since the corpus is assumed to be tokenized, lemmatized and filtered, and the corpus can be used by the topic modelling engines without further processing.  \n",
    "\n",
    "- Use the **1_extract_corpus_text** notebook to prepare this kind of corpus.\n",
    "- This is recommended for large corpora when the pre-process take a long and if the same filters and setup are to be used several times.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import topic_model_gui\n",
    "\n",
    "try:\n",
    "    \n",
    "    def fn_doc_index(corpus):\n",
    "        return domain_logic.compile_documents_by_filename(corpus.filenames)\n",
    "    \n",
    "    gui = topic_model_gui.PreparedCorpusUserInterface(data_folder=DATA_FOLDER, state=current_state(), fn_doc_index=fn_doc_index)\n",
    "    \n",
    "    gui.display(None)\n",
    "    \n",
    "except Exception as ex:\n",
    "    raise\n",
    "    logger.error(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color: green;'>MODEL</span> Store the Current Model or Load a Previously Computed Topic Model<span style='color: red; float: right'>OPTIONAL</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import glob\n",
    "import topic_model\n",
    "import topic_model_utility\n",
    "\n",
    "def get_persisted_model_paths():\n",
    "    return sorted([ x for x in glob.glob(os.path.join(DATA_FOLDER, '*.pickle')) ])\n",
    "\n",
    "def get_store_filename(identifier):\n",
    "    filename = os.path.join(DATA_FOLDER, 'topic_model.pickle')\n",
    "    filename = utility.path_add_date(filename)\n",
    "    filename = utility.path_add_suffix(filename, identifier)\n",
    "    return filename\n",
    "    \n",
    "def display_persist_topic_model_gui(state):\n",
    "    \n",
    "    gui = types.SimpleNamespace(\n",
    "        stored_path=widgets.Dropdown(description='Path', options=get_persisted_model_paths(), layout=widgets.Layout(width='40%')),\n",
    "        load=widgets.Button(description='Load', button_style='Success', layout=widgets.Layout(width='80px')),\n",
    "        store=widgets.Button(description='Store', button_style='Success', layout=widgets.Layout(width='80px')),\n",
    "        identifier=widgets.Text(description='Identifier', layout=widgets.Layout(width='300px')),\n",
    "        output=widgets.Output()\n",
    "    )\n",
    "    \n",
    "    boxes = widgets.VBox([\n",
    "        widgets.HBox([gui.stored_path, gui.load, gui.store, gui.identifier ]),\n",
    "        widgets.HBox([\n",
    "            widgets.Label(value=\"\", layout=widgets.Layout(width='40%')),\n",
    "            widgets.Label(value=\"Stored models will be named ./data/topic_model_yyyymmdd_$identifier$.pickle\", layout=widgets.Layout(width='40%')),\n",
    "        ]),\n",
    "        widgets.VBox([gui.output])\n",
    "    ])\n",
    "    \n",
    "    def load_handler(*args):\n",
    "        \n",
    "        with gui.output:\n",
    "            \n",
    "            if gui.stored_path.value is None:\n",
    "                print(\"Please specify which model to load.\")\n",
    "                return\n",
    "\n",
    "            state.data = topic_model.load_model(gui.stored_path.value)\n",
    "\n",
    "            topics = topic_model_utility.get_lda_topics(state.topic_model, n_tokens=20)\n",
    "\n",
    "            display(topics)\n",
    "\n",
    "    def store_handler(*args):\n",
    "        \n",
    "        gui.output.clear_output()\n",
    "\n",
    "        with gui.output:\n",
    "\n",
    "            if gui.identifier.value == '':\n",
    "                print(\"Please specify a unique identifier for the model.\")\n",
    "                return\n",
    "\n",
    "            if gui.identifier.value != utility.filename_whitelist(gui.identifier.value):\n",
    "                print(\"Please use ONLY valid filename characters in identifier.\")\n",
    "                return\n",
    "\n",
    "            filename = get_store_filename(gui.identifier.value)\n",
    "\n",
    "            topic_model.store_model(state.data, filename)\n",
    "\n",
    "            gui.stored_path.options = get_persisted_model_paths()\n",
    "            gui.stored_path.value = filename if filename in gui.stored_path.options else None\n",
    "\n",
    "            print('Model stored in file {}'.format(filename))\n",
    "            \n",
    "    gui.load.on_click(load_handler)\n",
    "    gui.store.on_click(store_handler)\n",
    "    \n",
    "    display(boxes)\n",
    "\n",
    "display_persist_topic_model_gui(current_state())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color: green;'>VISUALIZE</span> Display Topic's Word Distribution as a Wordcloud<span style='color: red; float: right'>TRY IT</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Display LDA topic's token wordcloud\n",
    "opts = { 'max_font_size': 100, 'background_color': 'white', 'width': 900, 'height': 600 }\n",
    "import wordcloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_wordcloud(df, token='token', weight='weight', figsize=(14, 14/1.618), **args):\n",
    "    token_weights = dict({ tuple(x) for x in df[[token, weight]].values })\n",
    "    image = wordcloud.WordCloud(**args,)\n",
    "    image.fit_words(token_weights)\n",
    "    plt.figure(figsize=figsize) #, dpi=100)\n",
    "    plt.imshow(image, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    \n",
    "def display_wordcloud(\n",
    "    state,\n",
    "    topic_id=0,\n",
    "    n_words=100,\n",
    "    output_format='Wordcloud',\n",
    "    gui=None\n",
    "):\n",
    "    def tick(n=None):\n",
    "        gui.progress.value = (gui.progress.value + 1) if n is None else n\n",
    "        \n",
    "    if gui.n_topics != state.num_topics:\n",
    "        gui.n_topics = state.num_topics\n",
    "        gui.topic_id.value = 0\n",
    "        gui.topic_id.max=state.num_topics - 1\n",
    "        \n",
    "    tick(1)\n",
    "    \n",
    "    try:\n",
    "        topic_token_weights = state.processed.topic_token_weights\n",
    "\n",
    "        df = topic_token_weights.loc[(topic_token_weights.topic_id == topic_id)]\n",
    "\n",
    "        tokens = topic_model_utility.get_topic_title(topic_token_weights, topic_id, n_tokens=n_words)\n",
    "        gui.text.value = 'ID {}: {}'.format(topic_id, tokens)\n",
    "\n",
    "        tick()\n",
    "\n",
    "        if output_format == 'Wordcloud':\n",
    "            plot_wordcloud(df, 'token', 'weight', max_words=n_words, **opts)\n",
    "        else:\n",
    "            tick()\n",
    "            df = topic_model_utility.get_topic_tokens(topic_token_weights, topic_id=topic_id, n_words=n_words)\n",
    "            tick()\n",
    "            display(df)\n",
    "    except IndexError:\n",
    "        print('No data for topic')\n",
    "    tick(0)\n",
    "    \n",
    "def display_wordcloud_gui(state):\n",
    "    \n",
    "    output_options = ['Wordcloud', 'Table']\n",
    "    text_id = 'tx02'\n",
    "    \n",
    "    gui = widgets_utility.WidgetUtility(\n",
    "        n_topics=state.num_topics,\n",
    "        text_id=text_id,\n",
    "        text=widgets_config.text(text_id),\n",
    "        topic_id=widgets.IntSlider(description='Topic ID', min=0, max=state.num_topics - 1, step=1, value=0, continuous_update=False),\n",
    "        word_count=widgets.IntSlider(description='#Words', min=5, max=250, step=1, value=25, continuous_update=False),\n",
    "        output_format=widgets.Dropdown(description='Format', options=output_options, value=output_options[0], layout=widgets.Layout(width=\"200px\")),\n",
    "        progress=widgets.IntProgress(min=0, max=4, step=1, value=0, layout=widgets.Layout(width=\"95%\"))\n",
    "    )\n",
    "\n",
    "    gui.prev_topic_id = gui.create_prev_id_button('topic_id', state.num_topics)\n",
    "    gui.next_topic_id = gui.create_next_id_button('topic_id', state.num_topics)\n",
    "\n",
    "    iw = widgets.interactive(\n",
    "        display_wordcloud,\n",
    "        state=widgets.fixed(state),\n",
    "        topic_id=gui.topic_id,\n",
    "        n_words=gui.word_count,\n",
    "        output_format=gui.output_format,\n",
    "        gui=widgets.fixed(gui)\n",
    "    )\n",
    "\n",
    "    display(widgets.VBox([\n",
    "        gui.text,\n",
    "        widgets.HBox([gui.prev_topic_id, gui.next_topic_id, gui.topic_id, gui.word_count, gui.output_format]),\n",
    "        gui.progress,\n",
    "        iw.children[-1]\n",
    "    ]))\n",
    "\n",
    "    iw.update()\n",
    "\n",
    "try:\n",
    "    display_wordcloud_gui(current_state())\n",
    "except topic_model_utility.TopicModelException as ex:\n",
    "    logger.info(ex)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color: green'>EXPLORE </span> pyLDAvis <span style='float: right; color: red'>TRY IT</span>\n",
    "http://www.aclweb.org/anthology/W14-3110 presented at the 2014 ACL Workshop on Interactive Language Learning, Visualization, and Interfaces in Baltimore on June 27, 2014.\n",
    "https://github.com/bmabey/pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis, pyLDAvis.gensim, pyLDAvis.sklearn\n",
    "import gensim\n",
    "pyLDAvis.enable_notebook()\n",
    "def display_pyLDAvis(state):\n",
    "    \n",
    "    try:\n",
    "        if isinstance(state.data.topic_model, textacy.tm.topic_model.TopicModel):\n",
    "            topic_model = state.data.topic_model.model\n",
    "        elif isinstance(state.data.topic_model, gensim.models.wrappers.LdaMallet):\n",
    "            topic_model = topic_model_utility.malletmodel2ldamodel(state.data.topic_model)\n",
    "        else:\n",
    "            topic_model = state.data.topic_model\n",
    "\n",
    "        if 'sklearn' in str(type(topic_model)):\n",
    "            p = pyLDAvis.sklearn.prepare(topic_model, state.data.g_corpus, state.data.id2term)\n",
    "        else:\n",
    "            p = pyLDAvis.gensim.prepare(topic_model, state.data.g_corpus, state.data.id2term)\n",
    "\n",
    "        display(p)\n",
    "    except Exception as ex:\n",
    "        logger.warning('This model cannot be visualized with pyLDAvis')\n",
    "        logger.error(ex)\n",
    "        \n",
    "display_pyLDAvis(current_state())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color: green;'>VISUALIZE</span> Display Topic's Word Distribution as a Chart<span style='color: red; float: right'>TRY IT</span>\n",
    "\n",
    "FIXME: Number of topics as specified in compute is not relevant for all topics. state.num_topics is to high for these models wich gives an error.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     3
    ]
   },
   "outputs": [],
   "source": [
    "# Display topic's word distribution\n",
    "import numpy as np\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "def plot_topic_word_distribution(tokens, **args):\n",
    "\n",
    "    source = bokeh.models.ColumnDataSource(tokens)\n",
    "\n",
    "    p = bokeh.plotting.figure(toolbar_location=\"right\", **args)\n",
    "\n",
    "    cr = p.circle(x='xs', y='ys', source=source)\n",
    "\n",
    "    label_style = dict(level='overlay', text_font_size='8pt', angle=np.pi/6.0)\n",
    "\n",
    "    text_aligns = ['left', 'right']\n",
    "    for i in [0, 1]:\n",
    "        label_source = bokeh.models.ColumnDataSource(tokens.iloc[i::2])\n",
    "        labels = bokeh.models.LabelSet(x='xs', y='ys', text_align=text_aligns[i], text='token', text_baseline='middle',\n",
    "                          y_offset=5*(1 if i == 0 else -1),\n",
    "                          x_offset=5*(1 if i == 0 else -1),\n",
    "                          source=label_source, **label_style)\n",
    "        p.add_layout(labels)\n",
    "\n",
    "    p.xaxis[0].axis_label = 'Token #'\n",
    "    p.yaxis[0].axis_label = 'Probability%'\n",
    "    p.ygrid.grid_line_color = None\n",
    "    p.xgrid.grid_line_color = None\n",
    "    p.axis.axis_line_color = None\n",
    "    p.axis.major_tick_line_color = None\n",
    "    p.axis.major_label_text_font_size = \"6pt\"\n",
    "    p.axis.major_label_standoff = 0\n",
    "    return p\n",
    "\n",
    "def display_topic_tokens(state, topic_id=0, n_words=100, output_format='Chart', gui=None):\n",
    "    \n",
    "    def tick(n=None):\n",
    "        gui.progress.value = (gui.progress.value + 1) if n is None else n\n",
    "        \n",
    "    if gui.n_topics != state.num_topics:\n",
    "        gui.n_topics = state.num_topics\n",
    "        gui.topic_id.value = 0\n",
    "        gui.topic_id.max=state.num_topics - 1\n",
    "        \n",
    "    tick(1)\n",
    "    \n",
    "    tokens = topic_model_utility.get_topic_tokens(state.processed.topic_token_weights, topic_id=topic_id, n_tokens=n_words).\\\n",
    "        copy()\\\n",
    "        .drop('topic_id', axis=1)\\\n",
    "        .assign(weight=lambda x: 100.0 * x.weight)\\\n",
    "        .sort_values('weight', axis=0, ascending=False)\\\n",
    "        .reset_index()\\\n",
    "        .head(n_words)\n",
    "    \n",
    "    if output_format == 'Chart':\n",
    "        tick()\n",
    "        tokens = tokens.assign(xs=tokens.index, ys=tokens.weight)\n",
    "        p = plot_topic_word_distribution(tokens, plot_width=1200, plot_height=500, title='', tools='box_zoom,wheel_zoom,pan,reset')\n",
    "        bokeh.plotting.show(p)\n",
    "        tick()\n",
    "    else:\n",
    "        display(tokens)\n",
    "        \n",
    "    tick(0)\n",
    "    \n",
    "def display_topic_distribution_gui(state):\n",
    "    \n",
    "    text_id = 'wc01'\n",
    "    output_options = ['Chart', 'Table']\n",
    "    \n",
    "    gui = widgets_utility.WidgetUtility(\n",
    "        n_topics=state.num_topics,\n",
    "        text_id=text_id,\n",
    "        text=widgets_config.text(text_id),\n",
    "        topic_id=widgets.IntSlider(description='Topic ID', min=0, max=state.num_topics - 1, step=1, value=0),\n",
    "        n_words=widgets.IntSlider(description='#Words', min=5, max=500, step=1, value=75),\n",
    "        output_format=widgets.Dropdown(description='Format', options=output_options, value=output_options[0], layout=widgets.Layout(width=\"200px\")),\n",
    "        progress=widgets.IntProgress(min=0, max=4, step=1, value=0, layout=widgets.Layout(width=\"95%\"))\n",
    "    )\n",
    "\n",
    "    gui.prev_topic_id = gui.create_prev_id_button('topic_id', state.num_topics)\n",
    "    gui.next_topic_id = gui.create_next_id_button('topic_id', state.num_topics)\n",
    "\n",
    "    iw = widgets.interactive(\n",
    "        display_topic_tokens,\n",
    "        state=widgets.fixed(state),\n",
    "        topic_id=gui.topic_id,\n",
    "        n_words=gui.n_words,\n",
    "        output_format=gui.output_format,\n",
    "        gui=widgets.fixed(gui)\n",
    "    )\n",
    "\n",
    "    display(widgets.VBox([\n",
    "        gui.text,\n",
    "        widgets.HBox([gui.prev_topic_id, gui.next_topic_id, gui.topic_id, gui.n_words, gui.output_format]),\n",
    "        gui.progress,\n",
    "        iw.children[-1]\n",
    "    ]))\n",
    "\n",
    "    iw.update()\n",
    "\n",
    "try:\n",
    "    display_topic_distribution_gui(current_state())\n",
    "except Exception as ex:\n",
    "    logger.error(ex)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color: green;'>VISUALIZE</span> Display Topic's Trend Over Time or Documents<span style='color: red; float: right'>TRY IT</span>\n",
    "- Displays topic's share over documents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Plot a topic's yearly weight over time in selected LDA topic model\n",
    "import math\n",
    "\n",
    "def plot_topic_trend(df, category_column, value_column, x_label=None, y_label=None, **figopts):\n",
    "    \n",
    "    xs = df[category_column].astype(np.str)\n",
    "    ys = df[value_column]\n",
    "    \n",
    "    figopts = utility.extend(dict(title='', toolbar_location=\"right\"), figopts)\n",
    "    \n",
    "    p = bokeh.plotting.figure(**figopts)\n",
    "\n",
    "    glyph = p.vbar(x=xs, top=ys, width=0.5, fill_color=\"#b3de69\")\n",
    "    \n",
    "    p.xaxis.major_label_orientation = math.pi/4\n",
    "    p.xgrid.grid_line_color = None\n",
    "    p.xaxis[0].axis_label = (x_label or category_column.title().replace('_', ' ')).title()\n",
    "    p.yaxis[0].axis_label = (y_label or value_column.title().replace('_', ' ')).title()\n",
    "    p.y_range.start = 0.0\n",
    "    p.x_range.range_padding = 0.01\n",
    "    \n",
    "    return p\n",
    "\n",
    "def display_topic_trend(\n",
    "    state,\n",
    "    topic_id,\n",
    "    year,\n",
    "    year_aggregate,\n",
    "    threshold=0.01,\n",
    "    output_format='Chart',\n",
    "    topic_changed=utility.noop\n",
    "):\n",
    "    figopts = dict(plot_width=1000, plot_height=700, title='', toolbar_location=\"right\")\n",
    "    \n",
    "    document_topic_weights = state.processed.document_topic_weights\n",
    "\n",
    "    topic_changed(topic_id)\n",
    "    \n",
    "    # FIXME VARYING ASPECT: name 'signed_year'\n",
    "    year_column = 'year'\n",
    "    \n",
    "    pivot_column = year_column if year is None else None\n",
    "    value_column = year_aggregate if year is None else 'weight'\n",
    "\n",
    "    df = document_topic_weights[(document_topic_weights.topic_id == topic_id)]\n",
    "    # FIXME MISSING YEAR IN FILENAME HACK\n",
    "    df = df[(df[year_column] > 0)]\n",
    "    \n",
    "    if year is not None:\n",
    "        # FIXME VARYING ASPECT: name 'signed_year'\n",
    "        df = df[(df[year_column] == year)]\n",
    "        \n",
    "    df = df[(df.weight > threshold)].reset_index()\n",
    "    \n",
    "    if len(df) == 0:\n",
    "        print('NO DATA')\n",
    "        return\n",
    "    \n",
    "    if year is None:\n",
    "        \n",
    "        min_year, max_year = df[year_column].min(), df[year_column].max()\n",
    "        figopts['x_range'] = list(map(str, range(min_year, max_year+1))) # utility.complete_value_range(df[category_column].unique(), str)\n",
    "        \n",
    "        df = df.groupby([year_column, 'topic_id']).agg([np.mean, np.max])['weight'].reset_index()\n",
    "        df.columns = [year_column, 'topic_id', 'mean', 'max']\n",
    "        category_column = year_column\n",
    "\n",
    "    else:\n",
    "        # FIXME: Varying ASPECTS\n",
    "        category_column = 'document_name'\n",
    "        df[category_column] = df.filename # df.treaty_id + ' ' + df.party1 + ' ' + df.party2\n",
    "        figopts['x_range'] = df[category_column].unique()\n",
    "        \n",
    "    if output_format == 'Table':\n",
    "        display(df)\n",
    "    else:\n",
    "        p = plot_topic_trend(df, category_column, value_column, **figopts)\n",
    "        bokeh.plotting.show(p)\n",
    "\n",
    "def display_topic_trend_gui(state):\n",
    "    \n",
    "    year_low, year_high = int(state.processed.year_period[0]), int(state.processed.year_period[1])\n",
    "    year_options = [ ('all years', None) ] + [ (str(x), x) for x in range(year_low, year_high + 1)]\n",
    "    \n",
    "    text_id = 'topic_share_plot'\n",
    "    \n",
    "    gui = widgets_utility.WidgetUtility(\n",
    "        n_topics=state.num_topics,\n",
    "        text_id=text_id,\n",
    "        text=widgets_config.text(text_id),\n",
    "        year=widgets.Dropdown(description='Year', options=year_options, value=None),\n",
    "        year_aggregate=widgets.Dropdown(description='Aggregate', options=['mean', 'max'], value='max', layout=widgets.Layout(width=\"160px\")),\n",
    "        threshold=widgets.FloatSlider(description='Threshold', min=0.0, max=0.25, step=0.01, value=0.10, continuous_update=False),\n",
    "        topic_id=widgets.IntSlider(description='Topic ID', min=0, max=state.num_topics - 1, step=1, value=0, continuous_update=False),\n",
    "        output_format=widgets.Dropdown(description='Format', options=['Chart', 'Table'], value='Chart', layout=widgets.Layout(width=\"160px\")),\n",
    "        progress=widgets.IntProgress(min=0, max=4, step=1, value=0, layout=widgets.Layout(width=\"340px\")),\n",
    "    )\n",
    "    \n",
    "    gui.prev_topic_id = gui.create_prev_id_button('topic_id', state.num_topics)\n",
    "    gui.next_topic_id = gui.create_next_id_button('topic_id', state.num_topics)\n",
    "    \n",
    "    def on_topic_changed(topic_id):\n",
    "        try:\n",
    "            if gui.n_topics != state.num_topics:\n",
    "                gui.n_topics = state.num_topics\n",
    "                gui.topic_id.value = 0\n",
    "                gui.topic_id.max = state.num_topics - 1\n",
    "\n",
    "            tokens = topic_model_utility.get_topic_title(state.processed.topic_token_weights, topic_id, n_tokens=200)\n",
    "            gui.text.value = 'ID {}: {}'.format(topic_id, tokens)\n",
    "        except:\n",
    "            gui.text.value = 'ID {}: NO DATA'.format(topic_id)\n",
    "            \n",
    "    iw = widgets.interactive(\n",
    "        display_topic_trend,\n",
    "        state=widgets.fixed(state),\n",
    "        topic_id=gui.topic_id,\n",
    "        year=gui.year,\n",
    "        year_aggregate=gui.year_aggregate,\n",
    "        threshold=gui.threshold,\n",
    "        output_format=gui.output_format,\n",
    "        topic_changed=widgets.fixed(on_topic_changed)\n",
    "    )\n",
    "\n",
    "    display(widgets.VBox([\n",
    "        gui.text,\n",
    "        widgets.HBox([gui.prev_topic_id, gui.next_topic_id, gui.year, gui.year_aggregate, gui.output_format]),\n",
    "        widgets.HBox([gui.topic_id, gui.threshold, gui.progress]),\n",
    "        iw.children[-1]\n",
    "    ]))\n",
    "    \n",
    "    iw.update()\n",
    "\n",
    "try:\n",
    "    display_topic_trend_gui(current_state())\n",
    "except Exception as ex:\n",
    "    logger.error(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color: green;'>VISUALIZE</span> Display Topic to Document Network<span style='color: red; float: right'>TRY IT</span>\n",
    "The green nodes are documents, and blue nodes are topics. The edges (lines) indicates the strength of a topic in the connected document. The width of the edge is proportinal to the strength of the connection. Note that only edges with a strength above the certain threshold are displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Visualize year-to-topic network by means of topic-document-weights\n",
    "from common.plot_utility import layout_algorithms, PlotNetworkUtility\n",
    "import domain_logic_vatican as domain_logic\n",
    "import gui_utility\n",
    "from common.network_utility import NetworkUtility, DISTANCE_METRICS, NetworkMetricHelper\n",
    "\n",
    "def plot_document_topic_network(network, layout, scale=1.0, titles=None):\n",
    "    tools = \"pan,wheel_zoom,box_zoom,reset,hover,previewsave\"\n",
    "    year_nodes, topic_nodes = NetworkUtility.get_bipartite_node_set(network, bipartite=0)  \n",
    "    \n",
    "    year_source = NetworkUtility.get_node_subset_source(network, layout, year_nodes)\n",
    "    topic_source = NetworkUtility.get_node_subset_source(network, layout, topic_nodes)\n",
    "    lines_source = NetworkUtility.get_edges_source(network, layout, scale=6.0, normalize=False)\n",
    "    \n",
    "    edges_alphas = NetworkMetricHelper.compute_alpha_vector(lines_source.data['weights'])\n",
    "    \n",
    "    lines_source.add(edges_alphas, 'alphas')\n",
    "    \n",
    "    p = bokeh.plotting.figure(plot_width=1000, plot_height=600, x_axis_type=None, y_axis_type=None, tools=tools)\n",
    "    \n",
    "    r_lines = p.multi_line(\n",
    "        'xs', 'ys', line_width='weights', alpha='alphas', color='black', source=lines_source\n",
    "    )\n",
    "    r_years = p.circle(\n",
    "        'x','y', size=40, source=year_source, color='lightgreen', level='overlay', line_width=1,alpha=1.0\n",
    "    )\n",
    "    \n",
    "    r_topics = p.circle('x','y', size=25, source=topic_source, color='skyblue', level='overlay', alpha=1.00)\n",
    "    \n",
    "    p.add_tools(bokeh.models.HoverTool(renderers=[r_topics], tooltips=None, callback=widgets_utility.wf.\\\n",
    "        glyph_hover_callback(topic_source, 'node_id', text_ids=titles.index, text=titles, element_id='nx_id1'))\n",
    "    )\n",
    "\n",
    "    text_opts = dict(x='x', y='y', text='name', level='overlay', x_offset=0, y_offset=0, text_font_size='8pt')\n",
    "    \n",
    "    p.add_layout(\n",
    "        bokeh.models.LabelSet(\n",
    "            source=year_source, text_color='black', text_align='center', text_baseline='middle', **text_opts\n",
    "        )\n",
    "    )\n",
    "    p.add_layout(\n",
    "        bokeh.models.LabelSet(\n",
    "            source=topic_source, text_color='black', text_align='center', text_baseline='middle', **text_opts\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return p\n",
    "        \n",
    "def display_document_topic_network(\n",
    "    layout_algorithm,\n",
    "    state,\n",
    "    threshold=0.10,\n",
    "    document_filters=None,\n",
    "    #parties=None,\n",
    "    #period=None,\n",
    "    ignores=None,\n",
    "    scale=1.0,\n",
    "    output_format='network',\n",
    "    document_index=None,\n",
    "    tick=utility.noop\n",
    "):\n",
    "\n",
    "    tick(1)\n",
    "    \n",
    "    corpus = current_corpus()\n",
    "    \n",
    "    corpus_docs = { x._.meta['document_id'] : x for x in gui_utility.get_documents_by_field_filters(corpus, document_index, document_filters) }\n",
    "    \n",
    "    topic_token_weights = state.processed.topic_token_weights\n",
    "    document_topic_weights = state.processed.document_topic_weights\n",
    "    \n",
    "    titles = topic_model_utility.get_topic_titles(topic_token_weights)\n",
    "\n",
    "    df = document_topic_weights[document_topic_weights.weight > threshold].reset_index()\n",
    "    \n",
    "    df = df[df.document_id.isin(list(corpus_docs.keys()))]\n",
    "    # FIXME VARYING ASPECT: filters\n",
    "    #if len(parties or []) > 0:\n",
    "    #    df = df[df.party1.isin(parties) | df.party2.isin(parties)]\n",
    "\n",
    "    #if len(period or []) == 2:\n",
    "    #    df = df[(df.signed_year>=period[0]) & (df.signed_year<=period[1])]\n",
    "        \n",
    "    if len(ignores or []) > 0:\n",
    "        df = df[~df.topic_id.isin(ignores)]\n",
    "\n",
    "    df['weight'] = utility.clamp_values(list(df.weight), (0.1, 2.0))\n",
    "\n",
    "    if len(df) == 0:\n",
    "        print('No data')\n",
    "        return\n",
    "    \n",
    "    # FIXME VARYING ASPECT: filters\n",
    "    df['title'] = df.filename # df.treaty_id + ' ' + df.party1 + ' ' + df.party2\n",
    "\n",
    "    network = NetworkUtility.create_bipartite_network(df, 'title', 'topic_id')\n",
    "    tick()\n",
    "\n",
    "    if output_format == 'network':\n",
    "        args = PlotNetworkUtility.layout_args(layout_algorithm, network, scale)\n",
    "        layout = (layout_algorithms[layout_algorithm])(network, **args)\n",
    "        tick()\n",
    "        p = plot_document_topic_network(network, layout, scale=scale, titles=titles)\n",
    "        bokeh.plotting.show(p)\n",
    "\n",
    "    elif output_format == 'table':\n",
    "        display(df)\n",
    "\n",
    "    tick(0)\n",
    "        \n",
    "def document_topic_network_gui(document_index, state, filter_options):\n",
    "    \n",
    "    lw = lambda w: widgets.Layout(width=w)\n",
    "    \n",
    "    text_id = 'nx_id1'\n",
    "    layout_options = [ 'Circular', 'Kamada-Kawai', 'Fruchterman-Reingold']\n",
    "    #party_preset_options = wti_index.get_party_preset_options()\n",
    "    #parties_options = [ x for x in wti_index.get_countries_list() if x not in ['ALL', 'ALL OTHER'] ]\n",
    "    year_min, year_max = state.processed.year_period\n",
    "    \n",
    "    n_topics = state.num_topics\n",
    "    document_filters = gui_utility.generate_field_filters(document_index, filter_options)\n",
    "    gui = types.SimpleNamespace(\n",
    "        document_filters=document_filters,\n",
    "        #group_by_columns=widgets.Dropdown(description='Group by', value=group_by_options[0][1], options=group_by_options, layout=lw('200px')),\n",
    "        text=widgets_config.text(text_id),\n",
    "        #period=widgets.IntRangeSlider(description='Time', min=year_min, max=year_min+5, step=1, value=(year_min, year_max), continues_update=False),\n",
    "        scale=widgets.FloatSlider(description='Scale', min=0.0, max=1.0, step=0.01, value=0.1, continues_update=False),\n",
    "        threshold=widgets.FloatSlider(description='Threshold', min=0.0, max=1.0, step=0.01, value=0.50, continues_update=False),\n",
    "        output_format=widgets_utility.dropdown('Output', { 'Network': 'network', 'Table': 'table' }, 'network', layout=lw('200px')),\n",
    "        layout=widgets_utility.dropdown('Layout', layout_options, 'Fruchterman-Reingold', layout=lw('250px')),\n",
    "        #parties=widgets.SelectMultiple(description='Parties', options=parties_options, value=['FRANCE'], rows=7, layout=lw('180px')),\n",
    "        #party_preset=widgets_config.dropdown('Presets', party_preset_options, None, layout=lw('180px')),\n",
    "        progress=widgets.IntProgress(min=0, max=4, step=1, value=0, layout=widgets.Layout(width=\"95%\")),\n",
    "        ignores=widgets.SelectMultiple(description='Ignore', options=[('', None)] + [ ('Topic #'+str(i), i) for i in range(0, n_topics) ], value=[], rows=8, layout=lw('200px')),\n",
    "        compute=widgets.Button(description='Compute', layout=lw('120px')),\n",
    "        output=widgets.Output(layout={'border': '1px solid black'})\n",
    "    )\n",
    "    \n",
    "    def tick(x=None):\n",
    "        gui.progress.value = gui.progress.value + 1 if x is None else x\n",
    "        \n",
    "    #def on_party_preset_change(change):  # pylint: disable=W0613\n",
    "    #    if gui.party_preset.value is None:\n",
    "    #        return\n",
    "    #    gui.parties.value = gui.parties.options if 'ALL' in gui.party_preset.value else gui.party_preset.value\n",
    "            \n",
    "    #gui.party_preset.observe(on_party_preset_change, names='value')\n",
    "    \n",
    "    def compute_callback_handler(*_args):\n",
    "        gui.output.clear_output()\n",
    "        with gui.output:\n",
    "            display_document_topic_network(\n",
    "                layout_algorithm=gui.layout.value,\n",
    "                state=state,\n",
    "                threshold=gui.threshold.value,\n",
    "                #parties=gui.parties,\n",
    "                document_filters=[ (x['field'], x['widget'].value) for x in gui.document_filters],\n",
    "                #period=gui.period,\n",
    "                ignores=gui.ignores.value,\n",
    "                scale=gui.scale.value,\n",
    "                output_format=gui.output_format.value,\n",
    "                document_index=document_index,\n",
    "                tick=tick\n",
    "            )\n",
    "\n",
    "    display(widgets.VBox([\n",
    "        widgets.HBox([\n",
    "            widgets.VBox([gui.layout, gui.threshold, gui.scale ]),  # , gui.period]), \n",
    "            widgets.VBox([ x['widget'] for x in gui.document_filters]),\n",
    "            #widgets.VBox([gui.parties, gui.party_preset]), \n",
    "            widgets.VBox([gui.ignores, gui.output_format]), \n",
    "            widgets.VBox([gui.compute, gui.progress]),\n",
    "        ]),\n",
    "        gui.output,\n",
    "        gui.text,\n",
    "    ]))\n",
    "    \n",
    "    gui.compute.on_click(compute_callback_handler)\n",
    "\n",
    "    #iw.update()\n",
    "\n",
    "try:\n",
    "    document_index = domain_logic.compile_documents(current_corpus())\n",
    "    document_topic_network_gui(\n",
    "        document_index,\n",
    "        current_state(),\n",
    "        filter_options=domain_logic.DOCUMENT_FILTERS\n",
    "    )\n",
    "except Exception as ex:\n",
    "    logger.error(ex)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color: green;'>VISUALIZE</span> Topic Trends Overview<span style='color: red; float: right'>TRY IT</span>\n",
    "\n",
    "- The topic shares  displayed as a scattered heatmap plot using gradient color based on topic's weight in document.\n",
    "- [Stanford’s Termite software](http://vis.stanford.edu/papers/termite) uses a similar visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_topic_relevance_by_year\n",
    "import bokeh.transform\n",
    "\n",
    "def get_topic_weight_by_year_or_document(document_topic_weights, key='mean', year=None):\n",
    "    pivot_column = 'year' if year is None else 'document_id'\n",
    "    #if df[(df.year == year)]\n",
    "    df = self.get_document_topic_weights(year) \\\n",
    "        .groupby([pivot_column,'topic_id']) \\\n",
    "        .agg(config.AGGREGATES[key])[['weight']].reset_index()\n",
    "    return df, pivot_column\n",
    "    \n",
    "def setup_glyph_coloring(df):\n",
    "    max_weight = df.weight.max()\n",
    "    #colors = list(reversed(bokeh.palettes.Greens[9]))\n",
    "    colors = ['#ffffff', '#f7fcf5', '#e5f5e0', '#c7e9c0', '#a1d99b', '#74c476', '#41ab5d', '#238b45', '#006d2c', '#00441b']\n",
    "    mapper = bokeh.models.LinearColorMapper(palette=colors, low=0.0, high=1.0) # low=df.weight.min(), high=max_weight)\n",
    "    color_transform = bokeh.transform.transform('weight', mapper)\n",
    "    color_bar = bokeh.models.ColorBar(color_mapper=mapper, location=(0, 0),\n",
    "                         ticker=bokeh.models.BasicTicker(desired_num_ticks=len(colors)),\n",
    "                         formatter=bokeh.models.PrintfTickFormatter(format=\" %5.2f\"))\n",
    "    return color_transform, color_bar\n",
    "\n",
    "def compute_int_range_categories(values):\n",
    "    categories = values.unique()\n",
    "    if all(map(utility.isint, categories)):\n",
    "        categories = sorted(list(map(int, categories)))\n",
    "        return list(map(str, categories))\n",
    "    else:\n",
    "        return sorted(list(categories))\n",
    "\n",
    "HEATMAP_FIGOPTS = dict(title=\"Topic heatmap\", toolbar_location=\"right\",  x_axis_location=\"above\", plot_width=1000)\n",
    "\n",
    "def plot_topic_relevance_by_year(df, xs, ys, flip_axis, titles, text_id, **figopts):\n",
    "\n",
    "    line_height = 7\n",
    "    if flip_axis is True:\n",
    "        xs, ys = ys, xs\n",
    "        line_height = 10\n",
    "\n",
    "    x_range = compute_int_range_categories(df[xs])\n",
    "    y_range = compute_int_range_categories(df[ys])\n",
    "    \n",
    "    color_transform, color_bar = setup_glyph_coloring(df)\n",
    "    \n",
    "    source = bokeh.models.ColumnDataSource(df)\n",
    "\n",
    "    if x_range is not None:\n",
    "        figopts['x_range'] = x_range\n",
    "\n",
    "    if y_range is not None:\n",
    "        figopts['y_range'] = y_range\n",
    "        figopts['plot_height'] = max(len(y_range) * line_height, 500)\n",
    "    \n",
    "    p = bokeh.plotting.figure(**figopts)\n",
    "\n",
    "    args = dict(x=xs, y=ys, source=source, alpha=1.0, hover_color='red')\n",
    "    \n",
    "    cr = p.rect(width=1, height=1, line_color=None, fill_color=color_transform, **args)\n",
    "\n",
    "    p.x_range.range_padding = 0\n",
    "    p.ygrid.grid_line_color = None\n",
    "    p.xgrid.grid_line_color = None\n",
    "    p.axis.axis_line_color = None\n",
    "    p.axis.major_tick_line_color = None\n",
    "    p.axis.major_label_text_font_size = \"8pt\"\n",
    "    p.axis.major_label_standoff = 0\n",
    "    p.xaxis.major_label_orientation = 1.0\n",
    "    p.add_layout(color_bar, 'right')\n",
    "    \n",
    "    p.add_tools(bokeh.models.HoverTool(tooltips=None, callback=widgets_utility.WidgetUtility.glyph_hover_callback(\n",
    "        source, 'topic_id', titles.index, titles, text_id), renderers=[cr]))\n",
    "    \n",
    "    return p\n",
    "\n",
    "def display_doc_topic_heatmap(state, key='max', flip_axis=False, glyph='Circle', year=None, year_aggregate=None, output_format=None):\n",
    "    try:\n",
    "\n",
    "        titles = topic_model_utility.get_topic_titles(state.processed.topic_token_weights, n_tokens=100)\n",
    "        \n",
    "        df = state.processed.document_topic_weights.copy()\n",
    "\n",
    "        if year is not None:\n",
    "            df = df[(df.signed_year == year)]\n",
    "\n",
    "        if year is None:\n",
    "            \n",
    "            ''' Display aggregate value grouped by year  '''\n",
    "            df = df.groupby(['signed_year', 'topic_id']).agg([np.mean, np.max])['weight'].reset_index()\n",
    "            df.columns = ['signed_year', 'topic_id', 'mean', 'max']\n",
    "            df['weight'] = df[year_aggregate]\n",
    "            df['signed_year'] = df.signed_year.astype(str)\n",
    "            category_column = 'signed_year'\n",
    "            \n",
    "        else:\n",
    "            ''' Display individual treaties for selected year  '''\n",
    "            df['treaty'] = df.treaty_id + ' ' + df.party1 + ' ' + df.party2\n",
    "            df = df[['treaty', 'treaty_id', 'topic_id', 'weight']]\n",
    "            category_column = 'treaty'  \n",
    "        \n",
    "        df['document_id'] = df.index.astype(str)\n",
    "        df['topic_id'] = df.topic_id.astype(str)\n",
    "         \n",
    "        if output_format.lower() == 'heatmap':\n",
    "            \n",
    "            p = plot_topic_relevance_by_year(\n",
    "                df,\n",
    "                xs=category_column,\n",
    "                ys='topic_id',\n",
    "                flip_axis=flip_axis,\n",
    "                titles=titles,\n",
    "                text_id='topic_relevance',\n",
    "                **HEATMAP_FIGOPTS)\n",
    "\n",
    "            bokeh.plotting.show(p)\n",
    "            \n",
    "        else:\n",
    "            display(df)\n",
    "        \n",
    "    except Exception as ex:\n",
    "        raise\n",
    "        logger.error(ex)\n",
    "        \n",
    "def doc_topic_heatmap_gui(state):\n",
    "\n",
    "    lw = lambda w: widgets.Layout(width=w)\n",
    "    \n",
    "    text_id = 'topic_relevance'\n",
    "    \n",
    "    year_min, year_max = state.processed.year_period\n",
    "    year_options = [ ('all years', None) ] + [ (x,x) for x in range(year_min, year_max + 1)]\n",
    "    \n",
    "    gui = types.SimpleNamespace(\n",
    "        text_id=text_id,\n",
    "        text=widgets_config.text(text_id),\n",
    "        flip_axis=widgets.ToggleButton(value=True, description='Flip', icon='', layout=lw(\"80px\")),\n",
    "        year=widgets.Dropdown(description='Year', options=year_options, value=None, layout=lw(\"160px\")),\n",
    "        year_aggregate=widgets.Dropdown(description='Aggregate', options=['mean', 'max'], value='max', layout=lw(\"160px\")),\n",
    "        output_format=widgets.Dropdown(description='Output', options=['Heatmap', 'Table'], value='Heatmap', layout=lw(\"180px\"))\n",
    "    )\n",
    "    \n",
    "    iw = widgets.interactive(\n",
    "        display_doc_topic_heatmap,\n",
    "        state=widgets.fixed(state),\n",
    "        flip_axis=gui.flip_axis,\n",
    "        year=gui.year,\n",
    "        year_aggregate=gui.year_aggregate,\n",
    "        output_format=gui.output_format\n",
    "    )\n",
    "\n",
    "    display(widgets.VBox([\n",
    "        widgets.HBox([gui.year, gui.year_aggregate, gui.output_format, gui.flip_axis ]),\n",
    "        widgets.HBox([iw.children[-1]]), gui.text\n",
    "    ]))\n",
    "\n",
    "    iw.update()\n",
    "\n",
    "try:\n",
    "    doc_topic_heatmap_gui(current_state())\n",
    "except Exception as ex:\n",
    "    logger.error(ex)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color: green;'>VISUALIZE</span> Topic Cooccurrence<span style='color: red; float: right'>TRY IT</span>\n",
    "\n",
    "Computes weighted graph of topics co-occurring in the same document. Topics are defined as co-occurring if they both exists  in the same document both having weights above threshold. Weight are number of co-occurrences (binary yes or no). Node size reflects topic proportions over the entire corpus (normalized document) length, and are computed in accordance to how node sizes are computed in LDAvis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Visualize topic co-occurrence\n",
    "\n",
    "import common.plot_utility as plot_utility\n",
    "import common.network_utility as network_utility\n",
    "import bokeh.plotting # import figure, show, output_notebook, output_file\n",
    "\n",
    "bokeh.plotting.output_notebook()\n",
    "\n",
    "def get_topic_titles(topic_token_weights, topic_id=None, n_words=100):\n",
    "    df_temp = topic_token_weights if topic_id is None else topic_token_weights[(topic_token_weights.topic_id==topic_id)]\n",
    "    df = df_temp\\\n",
    "            .sort_values('weight', ascending=False)\\\n",
    "            .groupby('topic_id')\\\n",
    "            .apply(lambda x: ' '.join(x.token[:n_words].str.title()))\n",
    "    return df\n",
    "\n",
    "# FIXME: add doc token length to df_documents\n",
    "def get_topic_proportions(corpus_documents, document_topic_weights):\n",
    "    topic_proportion = topic_model.compute_topic_proportions(document_topic_weights, corpus_documents)\n",
    "    return topic_proportion\n",
    "    \n",
    "def display_topic_co_occurrence_network(\n",
    "    tm_data,\n",
    "    parties=None,\n",
    "    period=None,\n",
    "    ignores=None,\n",
    "    threshold=0.10,\n",
    "    layout='Fruchterman-Reingold',\n",
    "    scale=1.0,\n",
    "    output_format='table'\n",
    "):\n",
    "    try:\n",
    "        \n",
    "        model_data = tm_data.compiled_data\n",
    "        \n",
    "        titles = topic_model_utility.get_topic_titles(model_data.topic_token_weights)\n",
    "        df = model_data.document_topic_weights\n",
    "        df['document_id'] = df.index\n",
    "        \n",
    "        node_sizes = topic_model.compute_topic_proportions(df, model_data.documents)\n",
    "\n",
    "        if ignores is not None:\n",
    "            df = df[~df.topic_id.isin(ignores)]\n",
    "            \n",
    "        if len(parties or []) > 0:\n",
    "            df = df[df.party1.isin(parties) | df.party2.isin(parties)]\n",
    "            \n",
    "        if period is not None:\n",
    "            df = df[df.signed_year.between(period[0], period[1], inclusive=True)]\n",
    "            \n",
    "        df = df.loc[(df.weight >= threshold)]\n",
    "        df = pd.merge(df, df, how='inner', left_on='document_id', right_on='document_id')\n",
    "        df = df.loc[(df.topic_id_x < df.topic_id_y)]\n",
    "        df = df.groupby([df.topic_id_x, df.topic_id_y]).size().reset_index()\n",
    "        df.columns = ['source', 'target', 'weight']\n",
    "        \n",
    "        if len(df) == 0:\n",
    "            print('No data. Please change selections.')\n",
    "            return\n",
    "        \n",
    "        if output_format == 'table':\n",
    "            display(df)\n",
    "        else:\n",
    "            network = network_utility.NetworkUtility.create_network(df, source_field='source', target_field='target', weight='weight')\n",
    "            p = plot_utility.PlotNetworkUtility.plot_network(\n",
    "                network=network,\n",
    "                layout_algorithm=layout,\n",
    "                scale=scale,\n",
    "                threshold=0.0,\n",
    "                node_description=titles,\n",
    "                node_proportions=node_sizes,\n",
    "                weight_scale=10.0,\n",
    "                normalize_weights=True,\n",
    "                element_id='cooc_id',\n",
    "                figsize=(900,500)\n",
    "            )\n",
    "            bokeh.plotting.show(p)\n",
    "\n",
    "    except Exception as x:\n",
    "        raise\n",
    "        print(\"No data: please adjust filters\")\n",
    "\n",
    "def topic_coocurrence_network_gui(wti_index, tm_data):\n",
    "    \n",
    "    lw = lambda w: widgets.Layout(width=w)\n",
    "    n_topics = tm_data.tm_model.num_topics\n",
    "    \n",
    "    model = tm_data.tm_model\n",
    "    text_id = 'cooc_id'\n",
    "    layout_options = [ 'Circular', 'Kamada-Kawai', 'Fruchterman-Reingold']\n",
    "    party_preset_options = wti_index.get_party_preset_options()\n",
    "    parties_options = [ x for x in wti_index.get_countries_list() if x != 'ALL OTHER' ]\n",
    "    year_min, year_max = tm_data.compiled_data.year_period\n",
    "    \n",
    "    gui = types.SimpleNamespace(\n",
    "        n_topics=n_topics,\n",
    "        text=widgets_utility.wf.create_text_widget(text_id),\n",
    "        period=widgets.IntRangeSlider(description='Time', min=year_min, max=year_max, step=1, value=(year_min, year_max), continues_update=False),\n",
    "        scale=widgets.FloatSlider(description='Scale', min=0.0, max=1.0, step=0.01, value=0.1, continues_update=False),\n",
    "        threshold=widgets.FloatSlider(description='Threshold', min=0.0, max=1.0, step=0.01, value=0.20, continues_update=False),\n",
    "        output_format=widgets_utility.dropdown('Output', { 'Network': 'network', 'Table': 'table' }, 'network', layout=lw('200px')),\n",
    "        layout=widgets_utility.dropdown('Layout', layout_options, 'Fruchterman-Reingold', layout=lw('250px')),\n",
    "        parties=widgets.SelectMultiple(description='Parties', options=parties_options, value=[], rows=7, layout=lw('180px')),\n",
    "        party_preset=widgets_config.dropdown('Presets', party_preset_options, None, layout=lw('180px')),\n",
    "        progress=widgets.IntProgress(min=0, max=4, step=1, value=0, layout=widgets.Layout(width=\"99%\")),\n",
    "        ignores=widgets.SelectMultiple(description='Ignore', options=[('', None)] + [ ('Topic #'+str(i), i) for i in range(0, n_topics) ], value=[], rows=8, layout=lw('180px')),\n",
    "    )\n",
    "    def tick(x=None):\n",
    "        gui.progress.value = gui.progress.value + 1 if x is None else x\n",
    "        \n",
    "    def on_party_preset_change(change):  # pylint: disable=W0613\n",
    "        if gui.party_preset.value is None:\n",
    "            return\n",
    "        gui.parties.value = gui.parties.options if 'ALL' in gui.party_preset.value else gui.party_preset.value\n",
    "            \n",
    "    gui.party_preset.observe(on_party_preset_change, names='value')\n",
    "     \n",
    "    iw = widgets.interactive(\n",
    "        display_topic_co_occurrence_network,\n",
    "        tm_data=widgets.fixed(tm_data),\n",
    "        parties=gui.parties,\n",
    "        period=gui.period,\n",
    "        ignores=gui.ignores,\n",
    "        threshold=gui.threshold,\n",
    "        layout=gui.layout,\n",
    "        scale=gui.scale,\n",
    "        output_format=gui.output_format\n",
    "    )\n",
    "    display(widgets.VBox([\n",
    "        gui.text,\n",
    "        widgets.HBox([\n",
    "            widgets.VBox([gui.layout, gui.threshold, gui.scale, gui.period]), \n",
    "            widgets.VBox([gui.parties, gui.party_preset]), \n",
    "            widgets.VBox([gui.ignores]), \n",
    "            widgets.VBox([gui.output_format, gui.progress]),\n",
    "        ]),\n",
    "        iw.children[-1]\n",
    "    ]))\n",
    "    iw.update()\n",
    "    \n",
    "try:\n",
    "    tm_data = get_current_model()\n",
    "    topic_coocurrence_network_gui(WTI_INDEX, tm_data)\n",
    "except Exception as ex:\n",
    "    logger.error(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color: green'>EXPLORE </span> Topic Similarity <span style='float: right; color: red'>WORK IN PROGRESS</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style='color: green'>EXPLORE </span> Topic Similarity Network<span style='float: right; color: red'>WORK IN PROGRESS</span>\n",
    "This plot displays topic similarity based on **euclidean or cosine distances** between the **topic-to-word vectors**. Please note that the computations can take some time to exceute, especially for larger LDA models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Visualization\n",
    "import types\n",
    "\n",
    "# if 'zy_data' not in globals():\n",
    "zy_data = types.SimpleNamespace(\n",
    "    basename=None,\n",
    "    network=None,\n",
    "    X_n_space=None,\n",
    "    X_n_space_feature_names=None,\n",
    "    distance_matrix=None,\n",
    "    metric=None,\n",
    "    topic_proportions=None,\n",
    "    n_words = 0\n",
    ")\n",
    "\n",
    "def plot_clustering_dendogram(clustering):\n",
    "    plt.figure(figsize=(16,6))\n",
    "    # https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.cluster.hierarchy.dendrogram.html\n",
    "    R = dendrogram(clustering)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def VectorSpaceHelper_compute_distance_matrix(X_n_space, metric='euclidean'):\n",
    "    # https://se.mathworks.com/help/stats/pdist.html\n",
    "    metric = metric.lower()\n",
    "    if metric == 'kullback–leibler': metric = VectorSpaceHelper.kullback_leibler_divergence\n",
    "    if metric == 'scipy.stats.entropy': metric = scipy.stats.entropy\n",
    "    #print(metric)\n",
    "    X = X_n_space.toarray() if hasattr(X_n_space, 'toarray') else X_n_space\n",
    "    #X_n_space += 0.00001\n",
    "    distances = distance.pdist(X, metric=metric)\n",
    "    #print(distances)\n",
    "    distance_matrix = distance.squareform(distances)\n",
    "    #print(distance_matrix)    \n",
    "    return distance_matrix\n",
    "    \n",
    "def display_correlation_network(\n",
    "    layout_algorithm,\n",
    "    threshold=0.10,\n",
    "    scale=1.0,\n",
    "    metric='Euclidean',\n",
    "    n_words=200,\n",
    "    output_format='Network'\n",
    "):\n",
    "    global state, zy_data, zy\n",
    "\n",
    "    try:\n",
    "\n",
    "        zy.progress.value = 1\n",
    "        metric = DISTANCE_METRICS[metric]\n",
    "\n",
    "        node_description = state.get_topics_tokens_as_text()\n",
    "        node_proportions = state.get_topic_proportions()\n",
    "\n",
    "        zy.progress.value = 2\n",
    "        if zy_data.network is None or state.basename != zy_data.basename or zy_data.metric != metric or zy_data.n_words != n_words:\n",
    "\n",
    "            zy_data.basename = state.basename\n",
    "            zy_data.n_words = n_words\n",
    "            zy_data.X_n_space, zy_data.X_n_space_feature_names = state.compute_topic_terms_vector_space(n_words=n_words)\n",
    "            \n",
    "            #print(zy_data.X_n_space.shape)\n",
    "            #print(zy_data.X_n_space_feature_names)\n",
    "            zy.progress.value = 3\n",
    "            zy_data.distance_matrix = VectorSpaceHelper_compute_distance_matrix(zy_data.X_n_space, metric=metric)\n",
    "            zy_data.network = None\n",
    "\n",
    "        edges_data = VectorSpaceHelper.lower_triangle_iterator(zy_data.distance_matrix, threshold)\n",
    "\n",
    "        zy.progress.value = 4\n",
    "        if output_format == 'List':\n",
    "            df = pd.DataFrame(edges_data, columns=['x', 'y', 'weight'])\n",
    "            zy.progress.value = 5\n",
    "            display(HTML(df.to_html()))\n",
    "        else:\n",
    "            zy.progress.value = 5\n",
    "            if zy_data.network is None:\n",
    "                zy_data.network = NetworkUtility.create_network_from_xyw_list(edges_data) # zy_data.distance_matrix)\n",
    "            zy.progress.value = 6\n",
    "            p = PlotNetworkUtility.plot_network(\n",
    "                network=zy_data.network,\n",
    "                layout_algorithm=layout_algorithm,\n",
    "                scale=scale,\n",
    "                threshold=threshold,\n",
    "                node_description=node_description,\n",
    "                node_proportions=node_proportions,\n",
    "                element_id='nx_id3',\n",
    "                figsize=(1000,600)\n",
    "            )\n",
    "            zy.progress.value = 6\n",
    "            show(p)\n",
    "\n",
    "        zy.progress.value = 7\n",
    "        zy.progress.value = 0\n",
    "    except Exception as ex:\n",
    "        # logger.exception(ex)\n",
    "        print('Error: {}'.format(ex))\n",
    "        print('Empty set: please change filters')\n",
    "        zy.progress.value = 0\n",
    "\n",
    "zy = widgets_utility.WidgetUtility(\n",
    "    n_topics=state.n_topics,\n",
    "    text_id='nx_id3',\n",
    "    text=wf.create_text_widget('nx_id3'),\n",
    "    scale=wf.create_float_slider('Scale', min=0.0, max=1.0, step=0.01, value=0.1),\n",
    "    year=wf.create_int_slider(\n",
    "        description='Year', min=state.min_year, max=state.max_year, step=1, value=state.min_year\n",
    "    ),\n",
    "    n_words=wf.create_int_slider(description='#words*', min=10, max=500, step=1, value=20),\n",
    "    metric=wf.create_select_widget(label='Metric*', values=list(DISTANCE_METRICS.keys()), default='Euclidean'),\n",
    "    threshold=wf.create_float_slider('Threshold', min=0.0, max=1.0, step=0.01, value=0.01),\n",
    "    output_format=wf.create_select_widget('Format', ['Network', 'List'], default='Network'),\n",
    "    layout=wf.create_select_widget('Layout', list(layout_algorithms.keys()), default='Fruchterman-Reingold'),\n",
    "    progress=wf.create_int_progress_widget(min=0, max=7, step=1, value=0, layout=widgets.Layout(width=\"90%\"))\n",
    ") \n",
    "    \n",
    "wy = widgets.interactive(\n",
    "    display_correlation_network,\n",
    "    layout_algorithm=zy.layout,\n",
    "    threshold=zy.threshold,\n",
    "    scale=zy.scale,\n",
    "    metric=zy.metric,\n",
    "    n_words=zy.n_words,\n",
    "    output_format=zy.output_format\n",
    ")\n",
    "\n",
    "display(widgets.VBox(\n",
    "    (zy.text, ) +\n",
    "    (widgets.HBox((zy.threshold,) + (zy.metric,) + (zy.output_format,)),) +\n",
    "    (widgets.HBox((zy.n_words,) + (zy.layout,) + (zy.scale,)),) +\n",
    "    (zy.progress,) +\n",
    "    (wy.children[-1],)))\n",
    "\n",
    "wy.update()\n"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit ('text_analytic_tools': pipenv)",
   "language": "python",
   "name": "python37564bittextanalytictoolspipenv8c3d4c9c6f39484cb74f0ad2d777602d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}