{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "import corpus_vectorizer\n",
    "\n",
    "class Test_DfTextReader(unittest.TestCase):\n",
    "    \n",
    "    def create_test_dataframe(self):\n",
    "        data = [ \n",
    "            (2000, 'A B C'),\n",
    "            (2000, 'B C D'), \n",
    "            (2001, 'C B'),\n",
    "            (2003, 'A B F'),\n",
    "            (2003, 'E B'),\n",
    "            (2003, 'F E E')\n",
    "        ]\n",
    "        df = pd.DataFrame(data, columns=['year', 'txt'])\n",
    "        return df\n",
    "    \n",
    "    def test_reader_with_all_documents(self):\n",
    "        df = self.create_test_dataframe()\n",
    "        reader = DfTextReader(df)\n",
    "        result = [x for x in reader]\n",
    "        expected = [('0', 'A B C'), ('1', 'B C D'), ('2', 'C B'), ('3', 'A B F'), ('4', 'E B'), ('5', 'F E E')]\n",
    "        self.assertEqual(expected, result)\n",
    "        self.assertEqual(['0', '1', '2', '3', '4', '5'], reader.filenames)\n",
    "        self.assertEqual([\n",
    "                types.SimpleNamespace(filename='0', year=2000),\n",
    "                types.SimpleNamespace(filename='1', year=2000),\n",
    "                types.SimpleNamespace(filename='2', year=2001),\n",
    "                types.SimpleNamespace(filename='3', year=2003),\n",
    "                types.SimpleNamespace(filename='4', year=2003),\n",
    "                types.SimpleNamespace(filename='5', year=2003)\n",
    "            ], reader.metadata\n",
    "        )\n",
    "        \n",
    "    def test_reader_with_given_year(self):\n",
    "        df = self.create_test_dataframe()\n",
    "        reader = DfTextReader(df, 2003)\n",
    "        result = [x for x in reader]\n",
    "        expected = [('0', 'A B F'), ('1', 'E B'), ('2', 'F E E')]\n",
    "        self.assertEqual(expected, result)\n",
    "        self.assertEqual(['0', '1', '2'], reader.filenames)\n",
    "        self.assertEqual([\n",
    "                types.SimpleNamespace(filename='0', year=2003),\n",
    "                types.SimpleNamespace(filename='1', year=2003),\n",
    "                types.SimpleNamespace(filename='2', year=2003)\n",
    "            ], reader.metadata\n",
    "        )\n",
    "\n",
    "class Test_DfVectorize(unittest.TestCase):\n",
    "    \n",
    "    def setUp(self):\n",
    "        pass\n",
    "    \n",
    "    def create_test_dataframe(self):\n",
    "        data = [ \n",
    "            (2000, 'A B C'),\n",
    "            (2000, 'B C D'), \n",
    "            (2001, 'C B'),\n",
    "            (2003, 'A B F'),\n",
    "            (2003, 'E B'),\n",
    "            (2003, 'F E E')\n",
    "        ]\n",
    "        df = pd.DataFrame(data, columns=['year', 'txt'])\n",
    "        return df\n",
    "    \n",
    "    def create_corpus(self):\n",
    "        df = self.create_test_dataframe()\n",
    "        reader = DfTextReader(df)\n",
    "        kwargs = dict(isalnum=False, to_lower=False, deacc=False, min_len=0, max_len=None, numerals=False)\n",
    "        corpus = text_corpus.ProcessedCorpus(reader, **kwargs)\n",
    "        return corpus\n",
    "    \n",
    "    def test_corpus_text_stream(self):\n",
    "        df = self.create_test_dataframe()\n",
    "        reader = DfTextReader(df)\n",
    "        corpus = text_corpus.CorpusTextStream(reader)\n",
    "        result = [ x for x in corpus.documents()]\n",
    "        expected = [('0', 'A B C'), ('1', 'B C D'), ('2', 'C B'), ('3', 'A B F'), ('4', 'E B'), ('5', 'F E E')]\n",
    "        self.assertEqual(expected, result)\n",
    "        \n",
    "    def test_corpus_token_stream(self):\n",
    "        df = self.create_test_dataframe()\n",
    "        reader = DfTextReader(df)\n",
    "        corpus = text_corpus.CorpusTokenStream(reader)\n",
    "        result = [ x for x in corpus.documents()]\n",
    "        expected = [('0', ['A', 'B', 'C']), ('1', ['B', 'C', 'D']), ('2', ['C', 'B']), ('3', ['A', 'B', 'F']), ('4', ['E', 'B']), ('5', ['F', 'E', 'E'])]\n",
    "        self.assertEqual(expected, result)\n",
    "\n",
    "    def test_processed_corpus_token_stream(self):\n",
    "        df = self.create_test_dataframe()\n",
    "        reader = DfTextReader(df)\n",
    "        kwargs = dict(isalnum=False, to_lower=False, deacc=False, min_len=0, max_len=None, numerals=False)\n",
    "        corpus = text_corpus.ProcessedCorpus(reader, **kwargs)\n",
    "        result = [ x for x in corpus.documents()]\n",
    "        expected = [('0', ['A', 'B', 'C']), ('1', ['B', 'C', 'D']), ('2', ['C', 'B']), ('3', ['A', 'B', 'F']), ('4', ['E', 'B']), ('5', ['F', 'E', 'E'])]\n",
    "        self.assertEqual(expected, result)\n",
    "        \n",
    "    def test_fit_transform_gives_document_term_matrix(self):\n",
    "        reader = DfTextReader(self.create_test_dataframe())\n",
    "        kwargs = dict(to_lower=False, deacc=False, min_len=1, max_len=None, numerals=False)\n",
    "        corpus = text_corpus.ProcessedCorpus(reader, isalnum=False, **kwargs)\n",
    "        vectorizer = corpus_vectorizer.CorpusVectorizer(lowercase=False)\n",
    "        vectorizer.fit_transform(corpus)\n",
    "        expected = np.asarray([\n",
    "            [1, 1, 1, 0, 0, 0],\n",
    "            [0, 1, 1, 1, 0, 0],\n",
    "            [0, 1, 1, 0, 0, 0],\n",
    "            [1, 1, 0, 0, 0, 1],\n",
    "            [0, 1, 0, 0, 1, 0],\n",
    "            [0, 0, 0, 0, 2, 1]\n",
    "        ])\n",
    "        self.assertTrue((expected == vectorizer.X).all())\n",
    "        results = vectorizer.vocabulary\n",
    "        expected = {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'F': 5, 'E': 4 }\n",
    "        self.assertEqual(expected, results)\n",
    "\n",
    "    def test_AxAt_of_document_term_matrix_gives_term_term_matrix(self):\n",
    "        \n",
    "        # Arrange\n",
    "        reader = DfTextReader(self.create_test_dataframe())\n",
    "        kwargs = dict(to_lower=False, deacc=False, min_len=1, max_len=None, numerals=False)\n",
    "        corpus = text_corpus.ProcessedCorpus(reader, isalnum=False, **kwargs)\n",
    "        vectorizer = corpus_vectorizer.CorpusVectorizer(lowercase=False)\n",
    "        vectorizer.fit_transform(corpus)\n",
    "        \n",
    "        # Act\n",
    "        term_term_matrix = np.dot(vectorizer.X.T, vectorizer.X)\n",
    "        \n",
    "        # Assert\n",
    "        expected = np.asarray([\n",
    "             [2, 2, 1, 0, 0, 1],\n",
    "             [2, 5, 3, 1, 1, 1],\n",
    "             [1, 3, 3, 1, 0, 0],\n",
    "             [0, 1, 1, 1, 0, 0],\n",
    "             [0, 1, 0, 0, 5, 2],\n",
    "             [1, 1, 0, 0, 2, 2]\n",
    "        ])\n",
    "        self.assertTrue((expected == term_term_matrix).all())\n",
    "        \n",
    "        term_term_matrix = scipy.sparse.triu(term_term_matrix, 1)\n",
    "        expected = np.asarray([\n",
    "             [0, 2, 1, 0, 0, 1],\n",
    "             [0, 0, 3, 1, 1, 1],\n",
    "             [0, 0, 0, 1, 0, 0],\n",
    "             [0, 0, 0, 0, 0, 0],\n",
    "             [0, 0, 0, 0, 0, 2],\n",
    "             [0, 0, 0, 0, 0, 0]\n",
    "        ])\n",
    "        \n",
    "        #print(term_term_matrix.todense())\n",
    "        #print(term_term_matrix)\n",
    "        coo = term_term_matrix\n",
    "        id2token = { i: t for t,i in vectorizer.vocabulary.items()}\n",
    "        cdf = pd.DataFrame({\n",
    "            'w1_id': coo.row,\n",
    "            'w2_id': coo.col,\n",
    "            'value': coo.data\n",
    "        })[['w1_id', 'w2_id', 'value']].sort_values(['w1_id', 'w2_id'])\\\n",
    "            .reset_index(drop=True)\n",
    "        cdf['w1'] = cdf.w1_id.apply(lambda x: id2token[x])\n",
    "        cdf['w2'] = cdf.w2_id.apply(lambda x: id2token[x])\n",
    "        print(cdf[['w1', 'w2', 'value']])\n",
    "        \n",
    "unittest.main(argv=['first-arg-is-ignored'], exit=False)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py,md"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
