{"cells":[{"cell_type":"markdown","metadata":{},"source":"# Word frequency distribution trends"},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":"%load_ext autoreload\n%autoreload 2\nimport os, sys\nimport westac.common.corpus_vectorizer as corpus_vectorizer\nimport westac.common.text_corpus as text_corpus\nimport westac.common.utility as utility\nimport numpy as np\nimport sklearn"},{"cell_type":"markdown","metadata":{},"source":"# Analysis\nhttps://github.com/davidmcclure/lint-analysis/tree/master/notebooks/2017\n"},{"cell_type":"markdown","metadata":{},"source":["## Goodness-of-fit to uniform distribution (chi-square)\n","\n","See [scipy.stats.chisquare](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chisquare.html): \n","\"*When just f_obs is given, it is assumed that the expected frequencies are uniform...*\"\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Loading data matrix...\nDone!\n"}],"source":"import os\nimport westac.common.corpus_vectorizer as corpus_vectorizer\nimport westac.common.text_corpus as text_corpus\n\nfrom scipy import stats\n\ndef vectorize_corpus(filename):\n\n    if not os.path.isfile(filename):\n        print('error: no such file: {}'.format(filename))\n        assert os.path.isfile(filename)\n\n    dump_tag = os.path.basename(filename).split('.')[0]\n\n    vectorizer = corpus_vectorizer.CorpusVectorizer()\n\n    if not vectorizer.dump_exists(dump_tag):\n\n        meta_extract = {\n            'year': r\"SOU (\\d{4})\\_.*\",\n            'serial_no': r\"SOU \\d{4}\\_(\\d+).*\"\n        }\n\n        print('Creating new corpus...')\n        corpus = text_corpus.create_corpus(filename, meta_extract)\n\n        print('Creating document-term matrix...')\n        _ = vectorizer.fit_transform(corpus)\n\n        print('Saving data matrix...')\n        vectorizer.dump(tag=dump_tag, folder='./output')\n\n    else:\n\n        print('Loading data matrix...')\n\n        vectorizer.load(dump_tag, folder='./output')\n\n    print('Done!')\n    return vectorizer\n\nfilename = './data/SOU_1945-1989.zip'\n    \nvectorizer = vectorize_corpus(filename)\n\nterm_year_matrix = vectorizer.group_by_year().T\nterm_year_matrix_n = vectorizer.normalize(term_year_matrix, axis=1, norm='l1')\n"},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>year</th>\n      <th>serial_no</th>\n      <th>document_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>SOU 1945_1 - Betänkande med förslag till utlän...</td>\n      <td>1945</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>SOU 1945_10 - Betänkande och förslag rörande e...</td>\n      <td>1945</td>\n      <td>10</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>SOU 1945_11 - Utredningar angående ekonomisk e...</td>\n      <td>1945</td>\n      <td>11</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>SOU 1945_14 - Socialpolitikens ekonomiska verk...</td>\n      <td>1945</td>\n      <td>14</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>SOU 1945_15 - Stadsplaneutredningen 1942..txt</td>\n      <td>1945</td>\n      <td>15</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <td>3124</td>\n      <td>SOU 1989_95 - Riksgäldskontoret - en finansför...</td>\n      <td>1989</td>\n      <td>95</td>\n      <td>3124</td>\n    </tr>\n    <tr>\n      <td>3125</td>\n      <td>SOU 1989_96 - Förenklad handläggning av ansökn...</td>\n      <td>1989</td>\n      <td>96</td>\n      <td>3125</td>\n    </tr>\n    <tr>\n      <td>3126</td>\n      <td>SOU 1989_97 - Vad händer med folkhögskolan_.txt</td>\n      <td>1989</td>\n      <td>97</td>\n      <td>3126</td>\n    </tr>\n    <tr>\n      <td>3127</td>\n      <td>SOU 1989_98 - Transplantation.txt</td>\n      <td>1989</td>\n      <td>98</td>\n      <td>3127</td>\n    </tr>\n    <tr>\n      <td>3128</td>\n      <td>SOU 1989_99 - Organdonation och transplantatio...</td>\n      <td>1989</td>\n      <td>99</td>\n      <td>3128</td>\n    </tr>\n  </tbody>\n</table>\n<p>3129 rows × 4 columns</p>\n</div>","text/plain":"                                               filename  year  serial_no  \\\n0     SOU 1945_1 - Betänkande med förslag till utlän...  1945          1   \n1     SOU 1945_10 - Betänkande och förslag rörande e...  1945         10   \n2     SOU 1945_11 - Utredningar angående ekonomisk e...  1945         11   \n3     SOU 1945_14 - Socialpolitikens ekonomiska verk...  1945         14   \n4         SOU 1945_15 - Stadsplaneutredningen 1942..txt  1945         15   \n...                                                 ...   ...        ...   \n3124  SOU 1989_95 - Riksgäldskontoret - en finansför...  1989         95   \n3125  SOU 1989_96 - Förenklad handläggning av ansökn...  1989         96   \n3126    SOU 1989_97 - Vad händer med folkhögskolan_.txt  1989         97   \n3127                  SOU 1989_98 - Transplantation.txt  1989         98   \n3128  SOU 1989_99 - Organdonation och transplantatio...  1989         99   \n\n      document_id  \n0               0  \n1               1  \n2               2  \n3               3  \n4               4  \n...           ...  \n3124         3124  \n3125         3125  \n3126         3126  \n3127         3127  \n3128         3128  \n\n[3129 rows x 4 columns]"},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["vectorizer.document_index\n",""]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":"\nyear_term_matrix   = vectorizer.group_by_year()\nyear_term_matrix_n = vectorizer.normalize(year_term_matrix, axis=1, norm='l1')\n# Y, categories = vectorizer.collapse_by_category('year')\n# (Y == year_term_matrix).all()\n\n#Ynw       = vectorizer.slice_tokens_by_count_threshold(Yn, 1)\n\n#Yx2, imap = vectorizer.pick_by_top_variance(500)\n\n#data       = stats.chisquare(Ynw, f_exp=None, ddof=0, axis=0)\n"},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":"copy_x : boolean, optional\nWhen pre-computing distances it is more numerically accurate to center the data first. If copy_x is True (default), then the original data is not modified, ensuring X is C-contiguous. If False, the original data is modified, and put back before the function returns, but small numerical differences may be introduced by subtracting and then adding the data mean, in this case it will also not ensure that data is C-contiguous which may cause a significant slowdown.\n\nalgorithm : “auto”, “full” or “elkan”, default=”auto”\nK-means algorithm to use. The classical EM-style algorithm is “full”. The “elkan” variation is more efficient by using the triangle inequality, but currently doesn’t support sparse data. “auto” chooses “elkan” for dense data and “full” for sparse data.\n"},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"(45, 5248040)\n[1 1 1 1 1 1 1 1 3 3 3 3 3 4 3 3 3 3 4 4 4 4 4 0 0 0 0 0 0 2 2 2 2 2 2 2 2\n 5 5 5 5 5 5 5 5]\n0.0007008333416259124\n6\n"}],"source":"from sklearn.cluster import KMeans\nimport numpy as np\n\n# https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html\n\nprint(year_term_matrix_n.shape)\nkmeans = KMeans(n_clusters=6, random_state=1337, precompute_distances='auto', n_init=10, n_jobs=4, algorithm='auto')\\\n    .fit(term_year_matrix_n)\n\nprint(kmeans.labels_)\nprint(kmeans.inertia_)\nprint(len(kmeans.cluster_centers_))\n\n# kmeans.predict()"},{"cell_type":"markdown","metadata":{},"source":"# Clustering (Ward and K-means)\n\nSee [this](https://stackabuse.com/hierarchical-clustering-with-python-and-scikit-learn/) tutorial.\n"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"from scipy.cluster.hierarchy import dendrogram, linkage\nfrom matplotlib import pyplot as plt\n\nlinked = linkage(Z.todense(), 'ward')\n\nlabelList = tokens_of_interest\n\nplt.figure(figsize=(10, 7))\ndendrogram(linked, orientation='top', labels=labelList, distance_sort='descending', show_leaf_counts=True)\nplt.show()\n"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# df_Zy.sum().where(lambda x: x>= 10000).sort_values().dropna()"},{"cell_type":"code","execution_count":null,"metadata":{"lines_to_next_cell":2},"outputs":[],"source":"#Xn = normalize(X, axis=1, norm='l1')\n#Y = collapse_to_year_matrix(X, df_documents)\n#df = pd.DataFrame(Y, columns=list(vectorizer.get_feature_names()))\n#df.to_excel('test.xlsx')\n\nif False:\n    \n    df = pd.DataFrame(X.toarray(), columns=list(vectorizer.get_feature_names()))\n    df['year'] = df.index + 45\n    df = df.set_index('year')\n    df['year'] =  pd.Series(df.index).apply(lambda x: documents[x][0])\n    %matplotlib inline\n    df[['krig']].plot() #.loc[df[\"000\"]==49]\n"}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}