{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process R data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys, os\n",
    "\n",
    "root_folder = os.path.join(os.getcwd().split('welfare_state_analytics')[0], 'welfare_state_analytics')\n",
    "\n",
    "sys.path = list(set(sys.path + [ root_folder ]))\n",
    "\n",
    "corpus_folder = os.path.join(root_folder, \"data/textblock_politisk\")\n",
    "\n",
    "import notebooks.corpus_data as corpus_data\n",
    "\n",
    "import ipywidgets\n",
    "#from beakerx import *\n",
    "#from beakerx.object import beakerx\n",
    "from IPython.display import display\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import penelope.corpus.vectorized_corpus as vectorized_corpus\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import notebooks.political_in_newspapers.corpus_data as corpus_data\n",
    "\n",
    "def load_meta_text_blocks_as_data_frame(corpus_folder):\n",
    "    \"\"\" Load censored corpus data \"\"\"\n",
    "\n",
    "    filename =  os.path.join(corpus_folder, corpus_data.meta_textblocks_filename)\n",
    "    df_meta = pd.read_csv(filename, compression='zip', header=0, sep=',', quotechar='\"', na_filter=False)\n",
    "    # df_meta = df_meta[['id', 'pred_bodytext']].drop_duplicates()\n",
    "    #df_meta.columns = [\"doc_id\", \"pred_bodytext\"]\n",
    "    #df_meta = df_meta.set_index(\"doc_id\")\n",
    "    return df_meta\n",
    "\n",
    "def load_reconstructed_text_corpus(corpus_folder):\n",
    "    filename = os.path.join(corpus_folder, corpus_data.reconstructed_text_corpus_file)\n",
    "    if not os.path.isfile(filename):\n",
    "        df_corpus = load_corpus_dtm_as_data_frame(corpus_folder)\n",
    "        df_vocabulary = load_vocabulary_file_as_data_frame(corpus_folder)\n",
    "        id2token = df_vocabulary['token'].to_dict()\n",
    "        df_reconstructed_text_corpus = (df_corpus.groupby('document_id')).apply( lambda x: ' '.join(flatten(x['tf'] * (x['token_id'].apply(lambda y: [id2token[y]])))))\n",
    "        df_reconstructed_text_corpus.to_csv(filename, compression='zip', header=0, sep=',', quotechar='\"')\n",
    "    else:\n",
    "        df_reconstructed_text_corpus = pd.read_csv(filename, compression='zip', header=None, sep=',', quotechar='\"')\n",
    "        df_reconstructed_text_corpus.columns = ['document_id', 'test']\n",
    "        df_reconstructed_text_corpus.set_index('document_id')\n",
    "\n",
    "    return df_reconstructed_text_corpus\n",
    "\n",
    "df = load_meta_text_blocks_as_data_frame(corpus_folder)\n",
    "rt = load_reconstructed_text_corpus(corpus_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load DTM, document index and vocabulary\n",
    "This data is loaded from CSV files exported from R (drm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import notebooks.political_in_newspapers.corpus_data as corpus_data\n",
    "df_corpus, df_document, df_vocabulary = corpus_data.load(corpus_folder)\n",
    "id2token = df_vocabulary['token'].to_dict()\n",
    "\n",
    "df_tf = df_corpus\\\n",
    "    .groupby(['document_id']).agg(\n",
    "        term_count=('tf', 'sum')\n",
    "    )\n",
    "df_document = df_document.merge(df_tf, how='inner', right_index=True, left_index=True)\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document size distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def plot_document_size_distribution():\n",
    "\n",
    "    df = df_document\\\n",
    "        .groupby('term_count')\\\n",
    "        .size()\n",
    "\n",
    "    dx = pd.DataFrame({ 'term_count': list(range(0, df.index.max() + 1))}).set_index('term_count')\n",
    "    df = dx.join(df.rename('x'), how='left').fillna(0).astype(np.int)\n",
    "\n",
    "    ax = df\\\n",
    "        .plot\\\n",
    "        .bar(figsize=(20,10), rot=45);\n",
    "\n",
    "    ticks = ax.xaxis.get_ticklocs();\n",
    "    ticklabels = [ l.get_text() for l in ax.xaxis.get_ticklabels() ];\n",
    "    ax.xaxis.set_ticks(ticks[::100]);\n",
    "    ax.xaxis.set_ticklabels(ticklabels[::100]);\n",
    "\n",
    "    return df\n",
    "\n",
    "df = plot_document_size_distribution()\n",
    "\n",
    "#print(df.describe())\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of documents per year and publication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_document\\\n",
    "    .groupby(['year', 'publication'])\\\n",
    "    .agg(document_count=('doc_id', 'nunique'))\\\n",
    "    .reset_index()\\\n",
    "    .set_index(['year', 'publication'])\n",
    "\n",
    "df\\\n",
    "    .unstack('publication')\\\n",
    "    .plot(kind='bar', subplots=True, figsize=(20,20), layout=(2,2), rot=45);\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numer of tokens per year and publication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_document\\\n",
    "    .groupby(['year', 'publication'])\\\n",
    "    .agg(term_count=('term_count', 'mean'))\\\n",
    "    .reset_index()\\\n",
    "    .set_index(['year', 'publication'])\\\n",
    "    .unstack('publication')\n",
    "\n",
    "df.to_excel('mean_tokens_per_year.xlsx')\n",
    "#display(df)    \n",
    "#df.plot(kind='bar', subplots=True, figsize=(25,25), layout=(2,2), rot=45);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print data sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('Corpus metrics, source \"dtm1.rds\", arrays drm$i, drm$j, drm$v')\n",
    "print('  {} max document ID'.format(df_corpus.document_id.max()))\n",
    "print('  {} unique document ID'.format(df_corpus.document_id.unique().shape[0]))\n",
    "print('  {} max token ID'.format(df_corpus.token_id.max()))\n",
    "print('  {} unique token ID'.format(df_corpus.token_id.unique().shape[0]))\n",
    "\n",
    "print('Document metrics, source \"dtm1.rds\", arrays drm$dimnames[1]')\n",
    "print('  {} max ID'.format(df_document.index.max()))\n",
    "print('  {} unique ID'.format(df_document.index.unique().shape[0]))\n",
    "print('  {} unique names'.format(df_document.doc_id.unique().shape[0]))\n",
    "\n",
    "print('Vocabulary metrics, source \"dtm1.rds\", arrays drm$dimnames[2]')\n",
    "print('  {} max ID'.format(df_vocabulary.index.max()))\n",
    "print('  {} unique ID'.format(df_vocabulary.index.unique().shape[0]))\n",
    "print('  {} unique token'.format(df_vocabulary.token.unique().shape[0]))\n",
    "\n",
    "#df_document.groupby('doc_id').filter(lambda x: len(x) > 1).head()\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit ('welfare_state_analytics': pipenv)",
   "language": "python",
   "name": "python37564bitwelfarestateanalyticspipenvb857bd21a5fc4575b483276067dc0241"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}